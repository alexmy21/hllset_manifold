{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLLSet Manifold - Refactored System Demo\n",
    "\n",
    "This notebook demonstrates the refactored three-layer architecture:\n",
    "\n",
    "1. **Kernel**: Stateless pure morphisms (absorb, union, intersection, difference)\n",
    "2. **HRT**: Immutable PyTorch-based data structure\n",
    "3. **Evolution**: Three-state model (In-Process → Current → History)\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Immutability**: All modifications create new objects with new hashes\n",
    "- **Content-addressing**: All objects named by SHA1 of content (no UUIDs, no randomness)\n",
    "- **Evolution**: System progresses through discrete steps (each step appends to history)\n",
    "- **Time Travel**: Can checkout historical states from Git and create new branches from them\n",
    "- **Git integration**: History pushed to Git, state is reconstructible from commit hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Imported binding MainInclude.eval was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.eval into Main conflicts with an existing identifier; ignored.\n",
      "WARNING: Imported binding MainInclude.include was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.include into Main conflicts with an existing identifier; ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "from core import (\n",
    "    Kernel, HLLSet,\n",
    "    ImmutableTensor, TensorEvolution, TensorEvolutionTriple,\n",
    "    HRT, HRTConfig, HRTEvolution, HRTEvolutionTriple,\n",
    "    compute_element_hash, compute_aggregate_hash, compute_structural_hash,\n",
    "    record_operation\n",
    ")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Layer 1: Kernel (Pure Morphisms)\n",
    "\n",
    "The kernel is a **stateless transformation engine**. It has:\n",
    "- No storage (no CAS, no history)\n",
    "- No side effects\n",
    "- Pure functions: same input → same output\n",
    "\n",
    "Morphism types (all return new HLLSets):\n",
    "- `absorb`: Set[str] → HLLSet\n",
    "- `union`: HLLSet × HLLSet → HLLSet\n",
    "- `intersection`: HLLSet × HLLSet → HLLSet\n",
    "- `difference`: HLLSet × HLLSet → HLLSet\n",
    "- `add`: HLLSet × tokens → HLLSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/tmp/ipykernel_71022/1159923313.py:30: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(f\"   A \\ B = {h_diff}\")\n",
      "/tmp/ipykernel_71022/1159923313.py:30: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(f\"   A \\ B = {h_diff}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "KERNEL: Stateless Pure Morphisms\n",
      "======================================================================\n",
      "\n",
      "1. absorb: Set[str] → HLLSet\n",
      "   A = absorb({'cat', 'dog', 'bird', 'fish'})\n",
      "       → HLLSet(bfcfb568..., |A|≈0.0)\n",
      "   B = absorb({'dog', 'fish', 'whale', 'shark'})\n",
      "       → HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "2. union: HLLSet × HLLSet → HLLSet\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "<PyCall.jlwrap (in a Julia function called from Python)\nJULIA: MethodError: no method matching iterate(::HllSet{10})\nThe function `iterate` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  iterate(!Matched::Base.GlobalRefIterator)\n   @ Base invalidation.jl:9\n  iterate(!Matched::Base.GlobalRefIterator, !Matched::Any)\n   @ Base invalidation.jl:9\n  iterate(!Matched::Compiler.AbsIntCycle, !Matched::Int64)\n   @ Base ~/.julia/juliaup/julia-1.12.3+0.x64.linux.gnu/share/julia/Compiler/src/inferencestate.jl:1016\n  ...\n\nStacktrace:\n [1] mapfilter(pred::Base.var\"#_unique_filter!##0#_unique_filter!##1\"{typeof(∉), typeof(push!), Set{Any}}, f::typeof(push!), itr::HllSet{10}, res::Vector{Any})\n   @ Base ./abstractset.jl:631\n [2] _grow!(pred!::Function, v::Vector{Any}, itrs::Tuple{HllSet{10}, HllSet{10}})\n   @ Base ./array.jl:3092\n [3] union!(::Vector{Any}, ::HllSet{10}, ::HllSet{10})\n   @ Base ./array.jl:3097\n [4] union(s::HllSet{10}, sets::HllSet{10})\n   @ Base ./abstractset.jl:57\n [5] _pyjlwrap_call(f::Function, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\n   @ PyCall ~/.julia/packages/PyCall/1gn3u/src/callback.jl:28\n [6] pyjlwrap_call(self_::Ptr{PyCall.PyObject_struct}, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\n   @ PyCall ~/.julia/packages/PyCall/1gn3u/src/callback.jl:44>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Morphism 2: union\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m2. union: HLLSet × HLLSet → HLLSet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m h_union = \u001b[43mkernel\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   A ∪ B = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh_union\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Morphism 3: intersection\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SGS/SGS_lib/hllset_manifold/core/kernel.py:80\u001b[39m, in \u001b[36mKernel.union\u001b[39m\u001b[34m(self, a, b)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munion\u001b[39m(\u001b[38;5;28mself\u001b[39m, a: HLLSet, b: HLLSet) -> HLLSet:\n\u001b[32m     75\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m    Union of two HLLSets.\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[33;03m    Morphism: HLLSet × HLLSet → HLLSet        \u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SGS/SGS_lib/hllset_manifold/core/hllset.py:111\u001b[39m, in \u001b[36mHLLSet.union\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m JULIA_AVAILABLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jl_hll \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m other._jl_hll \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m HLLSet(p_bits=\u001b[38;5;28mself\u001b[39m.p_bits)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m result_jl = \u001b[43mMain\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jl_hll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jl_hll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HLLSet(p_bits=\u001b[38;5;28mself\u001b[39m.p_bits, _jl_hll=result_jl)\n",
      "\u001b[31mRuntimeError\u001b[39m: <PyCall.jlwrap (in a Julia function called from Python)\nJULIA: MethodError: no method matching iterate(::HllSet{10})\nThe function `iterate` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  iterate(!Matched::Base.GlobalRefIterator)\n   @ Base invalidation.jl:9\n  iterate(!Matched::Base.GlobalRefIterator, !Matched::Any)\n   @ Base invalidation.jl:9\n  iterate(!Matched::Compiler.AbsIntCycle, !Matched::Int64)\n   @ Base ~/.julia/juliaup/julia-1.12.3+0.x64.linux.gnu/share/julia/Compiler/src/inferencestate.jl:1016\n  ...\n\nStacktrace:\n [1] mapfilter(pred::Base.var\"#_unique_filter!##0#_unique_filter!##1\"{typeof(∉), typeof(push!), Set{Any}}, f::typeof(push!), itr::HllSet{10}, res::Vector{Any})\n   @ Base ./abstractset.jl:631\n [2] _grow!(pred!::Function, v::Vector{Any}, itrs::Tuple{HllSet{10}, HllSet{10}})\n   @ Base ./array.jl:3092\n [3] union!(::Vector{Any}, ::HllSet{10}, ::HllSet{10})\n   @ Base ./array.jl:3097\n [4] union(s::HllSet{10}, sets::HllSet{10})\n   @ Base ./abstractset.jl:57\n [5] _pyjlwrap_call(f::Function, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\n   @ PyCall ~/.julia/packages/PyCall/1gn3u/src/callback.jl:28\n [6] pyjlwrap_call(self_::Ptr{PyCall.PyObject_struct}, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\n   @ PyCall ~/.julia/packages/PyCall/1gn3u/src/callback.jl:44>"
     ]
    }
   ],
   "source": [
    "# Create kernel\n",
    "kernel = Kernel(p_bits=10)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"KERNEL: Stateless Pure Morphisms\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Morphism 1: absorb\n",
    "print(\"\\n1. absorb: Set[str] → HLLSet\")\n",
    "h1 = kernel.absorb({'cat', 'dog', 'bird', 'fish'})\n",
    "h2 = kernel.absorb({'dog', 'fish', 'whale', 'shark'})\n",
    "print(f\"   A = absorb({{'cat', 'dog', 'bird', 'fish'}})\")\n",
    "print(f\"       → {h1}\")\n",
    "print(f\"   B = absorb({{'dog', 'fish', 'whale', 'shark'}})\")\n",
    "print(f\"       → {h2}\")\n",
    "\n",
    "# Morphism 2: union\n",
    "print(\"\\n2. union: HLLSet × HLLSet → HLLSet\")\n",
    "h_union = kernel.union(h1, h2)\n",
    "print(f\"   A ∪ B = {h_union}\")\n",
    "\n",
    "# Morphism 3: intersection\n",
    "print(\"\\n3. intersection: HLLSet × HLLSet → HLLSet\")\n",
    "h_inter = kernel.intersection(h1, h2)\n",
    "print(f\"   A ∩ B = {h_inter}\")\n",
    "\n",
    "# Morphism 4: difference\n",
    "print(\"\\n4. difference: HLLSet × HLLSet → HLLSet\")\n",
    "h_diff = kernel.difference(h1, h2)\n",
    "print(f\"   A \\ B = {h_diff}\")\n",
    "\n",
    "# Key property: kernel is stateless\n",
    "print(\"\\n5. Stateless Property\")\n",
    "print(f\"   - No storage of previous results\")\n",
    "print(f\"   - Same input always produces same output\")\n",
    "print(f\"   - A == absorb({{'cat', 'dog', 'bird', 'fish'}}): {h1 == kernel.absorb({'cat', 'dog', 'bird', 'fish'})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Immutability\n",
    "\n",
    "The kernel never modifies HLLSets - it always creates new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate immutability\n",
    "original = kernel.absorb({'a', 'b', 'c'})\n",
    "print(original)\n",
    "modified = kernel.add(original, 'x')\n",
    "\n",
    "print(f\"Original:  {original.name[:24]}... (|A|≈{original.cardinality():.0f})\")\n",
    "print(f\"Modified:  {modified.name[:24]}... (|A|≈{modified.cardinality():.0f})\")\n",
    "print(f\"Original unchanged: {original.name == kernel.absorb({'a', 'b', 'c'}).name}\")\n",
    "print(f\"\\nOriginal and modified are different objects: {original.name != modified.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Layer 2: Immutable Tensor (PyTorch Backend)\n",
    "\n",
    "The `ImmutableTensor` provides the foundation for all data structures:\n",
    "\n",
    "- PyTorch tensors with **clone-on-modify** semantics\n",
    "- Content-addressed naming (SHA1)\n",
    "- Parent pointers for lineage tracking\n",
    "- GPU-ready (tensors can be moved to CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"IMMUTABLE TENSOR: PyTorch Backend\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Genesis tensor\n",
    "print(\"\\n1. Genesis Tensor\")\n",
    "t_genesis = ImmutableTensor.zeros(100, 100)\n",
    "print(f\"   T₀ = zeros(100, 100)\")\n",
    "print(f\"      name = {t_genesis.name}\")\n",
    "print(f\"      shape = {t_genesis.shape}\")\n",
    "\n",
    "# All operations create new tensors\n",
    "print(\"\\n2. Clone-on-Modify Operations\")\n",
    "t1 = t_genesis.with_value((50, 50), 1.0)\n",
    "t2 = t_genesis.with_value((25, 25), 2.0)\n",
    "print(f\"   T₁ = T₀.with_value((50, 50), 1.0)\")\n",
    "print(f\"      name = {t1.name}\")\n",
    "print(f\"   T₂ = T₀.with_value((25, 25), 2.0)\")\n",
    "print(f\"      name = {t2.name}\")\n",
    "\n",
    "# Merge operation\n",
    "print(\"\\n3. Merge Operation (element-wise max)\")\n",
    "t_merged = t1.maximum(t2)\n",
    "print(f\"   T₃ = maximum(T₁, T₂)\")\n",
    "print(f\"      name = {t_merged.name}\")\n",
    "print(f\"   Value at (50, 50): {t_merged.data[50, 50].item()}\")\n",
    "print(f\"   Value at (25, 25): {t_merged.data[25, 25].item()}\")\n",
    "\n",
    "# Immutability guarantee\n",
    "print(\"\\n4. Immutability Guarantee\")\n",
    "print(f\"   T₀ unchanged: {t_genesis.name}\")\n",
    "print(f\"   T₀ == original genesis: {t_genesis.name == t_genesis.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Evolution Triple\n",
    "\n",
    "The generic `TensorEvolution` class manages three-state evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evolution manager\n",
    "print(\"\\n5. Tensor Evolution Manager\")\n",
    "evolution = TensorEvolution(t_genesis)\n",
    "print(f\"   Initial triple: {evolution.triple}\")\n",
    "\n",
    "# Ingest new data\n",
    "new_data = ImmutableTensor.zeros(100, 100).with_value((10, 10), 5.0)\n",
    "evolution.ingest(new_data)\n",
    "print(f\"   After ingest: {evolution.triple}\")\n",
    "\n",
    "# Evolve\n",
    "def merge_fn(in_proc, curr):\n",
    "    return in_proc.maximum(curr)\n",
    "\n",
    "def commit_fn(tensor):\n",
    "    print(f\"     Committing tensor {tensor.name[:20]}...\")\n",
    "    return tensor.name\n",
    "\n",
    "evolution.evolve(merge_fn, commit_fn)\n",
    "print(f\"   After evolve: {evolution.triple}\")\n",
    "print(f\"   Lineage: {[h[:16] + '...' for h in evolution.get_lineage()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Layer 3: HRT Evolution (Three-State Model)\n",
    "\n",
    "The **Hash Relational Tensor (HRT)** combines:\n",
    "- **Adjacency Matrix (AM)**: Relationship structure using `ImmutableTensor`\n",
    "- **HLLSet Lattice W**: Basic HLLSets for composition\n",
    "- **Covers**: Optimal compositions (optional cache)\n",
    "\n",
    "### Evolution Cycle\n",
    "\n",
    "```\n",
    "Step 1: Ingest → Set in_process\n",
    "Step 2: Evolve → Merge in_process+current, commit current\n",
    "Step 3: Cycle repeats\n",
    "```\n",
    "\n",
    "The shift to future: In-Process becomes Current, Current goes to History."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"HRT EVOLUTION: Three-State Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Setup\n",
    "kernel = Kernel(p_bits=8)\n",
    "config = HRTConfig(p_bits=8, h_bits=16)\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"   Dimension: {config.dimension}\")\n",
    "print(f\"   Basic HLLSets: {config.num_basic_hllsets}\")\n",
    "\n",
    "# Create evolution manager\n",
    "print(\"\\n1. Genesis State\")\n",
    "evolution = HRTEvolution(config)\n",
    "genesis = evolution.get_current()\n",
    "print(f\"   HRT₀ (genesis)\")\n",
    "print(f\"      name = {genesis.name}\")\n",
    "print(f\"      step = {genesis.step_number}\")\n",
    "print(f\"      am_entries = {len(genesis.am.nonzero_entries())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution Cycle 1\n",
    "print(\"\\n2. Evolution Cycle 1: Ingest → Merge → Commit\")\n",
    "\n",
    "# Step 1: Ingest\n",
    "data1 = {\n",
    "    'camera': {'red', 'green', 'blue', 'yellow'},\n",
    "    'microphone': {'low', 'mid', 'high'}\n",
    "}\n",
    "print(f\"   Ingest: {list(data1.keys())}\")\n",
    "evolution.ingest(data1, kernel)\n",
    "print(f\"   In-process HRT created\")\n",
    "print(f\"      AM entries: {len(evolution.triple.in_process.am.nonzero_entries())}\")\n",
    "\n",
    "# Step 2: Evolve (merge + commit)\n",
    "def mock_commit(hrt):\n",
    "    \"\"\"Mock Git commit - would save to persistent store.\"\"\"\n",
    "    return hrt.name\n",
    "\n",
    "evolution.evolve(kernel, mock_commit)\n",
    "\n",
    "hrt1 = evolution.get_current()\n",
    "print(f\"   After evolve:\")\n",
    "print(f\"      HRT₁ name = {hrt1.name}\")\n",
    "print(f\"      step = {hrt1.step_number}\")\n",
    "print(f\"      am_entries = {len(hrt1.am.nonzero_entries())}\")\n",
    "print(f\"      parent = {hrt1.parent_hrt[:32] if hrt1.parent_hrt else 'genesis'}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution Cycle 2\n",
    "print(\"\\n3. Evolution Cycle 2\")\n",
    "data2 = {\n",
    "    'thermometer': {'hot', 'warm', 'cold'},\n",
    "    'pressure': {'high_p', 'low_p'}\n",
    "}\n",
    "print(f\"   Ingest: {list(data2.keys())}\")\n",
    "evolution.ingest(data2, kernel)\n",
    "evolution.evolve(kernel, mock_commit)\n",
    "\n",
    "hrt2 = evolution.get_current()\n",
    "print(f\"   After evolve:\")\n",
    "print(f\"      HRT₂ name = {hrt2.name}\")\n",
    "print(f\"      step = {hrt2.step_number}\")\n",
    "print(f\"      am_entries = {len(hrt2.am.nonzero_entries())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineage\n",
    "print(\"\\n4. Lineage (Commit History)\")\n",
    "lineage = evolution.get_lineage()\n",
    "print(f\"   History chain:\")\n",
    "for i, h in enumerate(lineage):\n",
    "    marker = \" ← HEAD\" if i == len(lineage) - 1 else \"\"\n",
    "    print(f\"      [{i}] {h}{marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projections\n",
    "print(\"\\n5. Future/Past Projections\")\n",
    "current_hrt = evolution.get_current()\n",
    "\n",
    "# Future projection: columns → rows\n",
    "future = current_hrt.project_future([2, 3, 4, 5])\n",
    "print(f\"   Future projection (cols → rows): shape {future.shape}\")\n",
    "print(f\"      Top activations: {torch.topk(future.data, 3).values.tolist()}\")\n",
    "\n",
    "# Past projection: rows → columns\n",
    "past = current_hrt.project_past([0, 1, 2])\n",
    "print(f\"   Past projection (rows → cols): shape {past.shape}\")\n",
    "print(f\"      Top activations: {torch.topk(past.data, 3).values.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HRT Immutability\n",
    "\n",
    "All HRT operations create new HRTs. The original is never modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n6. HRT Immutability Verification\")\n",
    "current = evolution.get_current()\n",
    "original_name = current.name\n",
    "\n",
    "# Try to \"modify\" the AM\n",
    "modified_am = current.am.with_entry(0, 0, 5.0)\n",
    "\n",
    "print(f\"   Original HRT name: {current.name[:40]}...\")\n",
    "print(f\"   Modified AM name:  {modified_am.name[:40]}...\")\n",
    "print(f\"   Names different:   {current.name != modified_am.name}\")\n",
    "print(f\"   Original unchanged: {current.name == original_name}\")\n",
    "\n",
    "# The HRT with modified AM would be a new HRT\n",
    "new_hrt = HRT(\n",
    "    config=current.config,\n",
    "    am=modified_am,\n",
    "    lattice=current.lattice,\n",
    "    parent_hrt=current.name\n",
    ")\n",
    "print(f\"\\n   New HRT from modified AM:\")\n",
    "print(f\"      name = {new_hrt.name[:40]}...\")\n",
    "print(f\"      parent = {new_hrt.parent_hrt[:40]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Content Addressing\n",
    "\n",
    "All elements in the system are named by their content. No randomness, no UUIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CONTENT ADDRESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Two Types of Hashes\")\n",
    "print(\"   - Element hash: 32/64-bit (for tokens)\")\n",
    "print(\"   - Aggregate hash: SHA1 (for HLLSets, Tensors, HRTs)\")\n",
    "\n",
    "# Element hash\n",
    "print(\"\\n2. Element Hash Example\")\n",
    "h1 = compute_element_hash(\"hello\", bits=64)\n",
    "h2 = compute_element_hash(\"hello\", bits=64)\n",
    "h3 = compute_element_hash(\"world\", bits=64)\n",
    "print(f\"   hash('hello') = {h1}\")\n",
    "print(f\"   hash('hello') = {h2}\")\n",
    "print(f\"   hash('world') = {h3}\")\n",
    "print(f\"   Deterministic: {h1 == h2}\")\n",
    "\n",
    "# Aggregate hash\n",
    "print(\"\\n3. Aggregate Hash Example\")\n",
    "kernel = Kernel()\n",
    "hll1 = kernel.absorb({'a', 'b', 'c'})\n",
    "hll2 = kernel.absorb({'a', 'b', 'c'})\n",
    "hll3 = kernel.absorb({'x', 'y', 'z'})\n",
    "print(f\"   HLLSet({{'a', 'b', 'c'}}) = {hll1.name}\")\n",
    "print(f\"   HLLSet({{'a', 'b', 'c'}}) = {hll2.name}\")\n",
    "print(f\"   HLLSet({{'x', 'y', 'z'}}) = {hll3.name}\")\n",
    "print(f\"   Same content → same hash: {hll1.name == hll2.name}\")\n",
    "print(f\"   Different content → different hash: {hll1.name != hll3.name}\")\n",
    "\n",
    "# Structural hash\n",
    "print(\"\\n4. Structural Hash (for composed objects)\")\n",
    "name1 = compute_structural_hash(\"am_hash_abc\", \"lattice_hash_xyz\")\n",
    "name2 = compute_structural_hash(\"am_hash_abc\", \"lattice_hash_xyz\")\n",
    "name3 = compute_structural_hash(\"am_hash_def\", \"lattice_hash_xyz\")\n",
    "print(f\"   struct('abc', 'xyz') = {name1}\")\n",
    "print(f\"   struct('abc', 'xyz') = {name2}\")\n",
    "print(f\"   struct('def', 'xyz') = {name3}\")\n",
    "print(f\"   Deterministic: {name1 == name2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cover Computation\n",
    "\n",
    "A **Cover** represents an HLLSet as a composition of basic HLLSets from the lattice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COVER COMPUTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get current HRT and create a target HLLSet\n",
    "hrt = evolution.get_current()\n",
    "target = kernel.absorb({'red', 'green', 'hot', 'high_p'})\n",
    "\n",
    "print(f\"\\nTarget HLLSet: {target}\")\n",
    "\n",
    "# Compute cover\n",
    "cover = hrt.compute_cover(target, kernel)\n",
    "\n",
    "print(f\"\\nComputed Cover:\")\n",
    "print(f\"   target_hash: {cover.target_hash}\")\n",
    "print(f\"   size: {cover.size}\")\n",
    "print(f\"   row_indices: {sorted(cover.row_indices)[:10]}{'...' if len(cover.row_indices) > 10 else ''}\")\n",
    "print(f\"   col_indices: {sorted(cover.col_indices)[:10]}{'...' if len(cover.col_indices) > 10 else ''}\")\n",
    "print(f\"   cover_hash: {cover.name}\")\n",
    "\n",
    "# Add cover to HRT\n",
    "hrt_with_cover = hrt.with_cover(cover)\n",
    "print(f\"\\nHRT with cached cover:\")\n",
    "print(f\"   covers: {len(hrt_with_cover.covers)}\")\n",
    "print(f\"   new HRT name: {hrt_with_cover.name[:40]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Time Travel (History Navigation)\n",
    "\n",
    "**Important distinction:**\n",
    "- **Evolution steps are irreversible** - you cannot \"undo\" a merge (like you cannot undo a Git commit)\n",
    "- **But you can time travel** - checkout any historical state and start a new branch from there\n",
    "\n",
    "This is exactly like Git:\n",
    "\n",
    "\n",
    "The original timeline continues unchanged. Time travel creates a **new parallel timeline**.\n",
    "\n",
    "### Implementation\n",
    "- Checkout: Load HRT from Git by hash → create new Evolution manager from it\n",
    "- Branch: Continue evolution from that historical point\n",
    "- Merge: Later, branches can be merged (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TIME TRAVEL: Checkout Historical State\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Current timeline\n",
    "print(\"\n",
    "1. Current Timeline (Linear Evolution)\")\n",
    "lineage = evolution.get_lineage()\n",
    "print(f\"   Number of states: {len(lineage)}\")\n",
    "print(f\"   Current HEAD: {lineage[-1][:24]}...\")\n",
    "print(f\"   Current step: {evolution.get_current().step_number}\")\n",
    "\n",
    "# Simulate time travel: checkout historical state\n",
    "print(\"\n",
    "2. Time Travel: Checkout Historical State\")\n",
    "historical_hash = lineage[1]  # Go back to state 1\n",
    "print(f\"   Target state: {historical_hash[:24]}...\")\n",
    "\n",
    "# In real system, this would load from Git:\n",
    "# historical_hrt = git_checkout(historical_hash)\n",
    "# For demo, we use the evolution manager's reference\n",
    "print(\"   (In real system: git checkout <hash>)\")\n",
    "\n",
    "# Create new evolution branch from historical state\n",
    "print(\"\n",
    "3. Create New Branch from Historical State\")\n",
    "\n",
    "# Get the historical HRT (in real system, load from Git)\n",
    "historical_hrt = evolution.get_current()  # Simulating loaded state\n",
    "\n",
    "# Create new evolution manager starting from this state\n",
    "branch_evolution = HRTEvolution(config, genesis_hrt=historical_hrt)\n",
    "print(f\"   New branch created from step {branch_evolution.get_current().step_number}\")\n",
    "\n",
    "# Continue evolution on new branch\n",
    "print(\"\n",
    "4. Continue Evolution on New Branch\")\n",
    "branch_data = {\"alt_sensor\": {\"alpha\", \"beta\", \"gamma\"}}\n",
    "branch_evolution.ingest(branch_data, kernel)\n",
    "branch_evolution.evolve(kernel, mock_commit)\n",
    "\n",
    "print(f\"   Branch current step: {branch_evolution.get_current().step_number}\")\n",
    "print(f\"   Branch HRT: {branch_evolution.get_current().name[:24]}...\")\n",
    "\n",
    "# Original timeline unchanged\n",
    "print(\"\n",
    "5. Original Timeline Unchanged\")\n",
    "print(f\"   Original HEAD still at: {evolution.get_current().name[:24]}...\")\n",
    "print(f\"   Original step: {evolution.get_current().step_number}\")\n",
    "\n",
    "print(\"\n",
    "✓ Time travel creates parallel timeline, doesn't alter history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Representation of Time Travel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## System Invariants\n",
    "\n",
    "Summary of the key invariants maintained by the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SYSTEM INVARIANTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n✓ 1. Immutability\")\n",
    "print(\"   - Objects never change after creation\")\n",
    "print(\"   - All 'modifications' create new objects\")\n",
    "print(\"   - Parent pointers link old to new\")\n",
    "\n",
    "print(\"\\n✓ 2. Idempotency\")\n",
    "print(\"   - Same inputs → same outputs\")\n",
    "print(\"   - No side effects in kernel operations\")\n",
    "print(\"   - Replaying operations yields same result\")\n",
    "\n",
    "print(\"\\n✓ 3. Content Addressing\")\n",
    "print(\"   - Names are hashes of content\")\n",
    "print(\"   - No randomness, no UUIDs\")\n",
    "print(\"   - Deterministic across time and space\")\n",
    "\n",
    "print(\"\\n✓ 4. Evolution Model\")\n",
    "print(\"   - Three states: In-Process → Current → History\")\n",
    "print(\"   - Shift to future: commit current, merge in-process\")\n",
    "print(\"   - History is in Git, not in memory\")\n",
    "\n",
    "print(\"\\n✓ 5. Kernel Statelessness\")\n",
    "print(\"   - Kernel has no storage\")\n",
    "print(\"   - Pure functions only\")\n",
    "print(\"   - All state in HRT (managed by OS)\")\n",
    "\n",
    "print(\"\\n✓ 6. PyTorch Backend\")\n",
    "print(\"   - Tensors support GPU acceleration\")\n",
    "print(\"   - Clone-on-modify ensures immutability\")\n",
    "print(\"   - Efficient memory sharing where possible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This refactored system provides:\n",
    "\n",
    "| Component | Responsibility | Key Property |\n",
    "|-----------|---------------|--------------|\n",
    "| **Kernel** | Pure morphisms | Stateless, deterministic |\n",
    "| **HRT** | Operation data structure | Immutable, PyTorch-based |\n",
    "| **Evolution** | State management | Three-state cycle |\n",
    "| **Git** | Persistent storage | Content-addressed history |\n",
    "\n",
    "### Evolution Cycle\n",
    "\n",
    "```\n",
    "    ┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n",
    "    │ In-Process  │ ──→ │   Current   │ ──→ │   History   │\n",
    "    │ (new data)  │     │ (active)    │     │ (Git)       │\n",
    "    └─────────────┘     └─────────────┘     └─────────────┘\n",
    "           ↑                                         │\n",
    "           └──────────── Shift to Future ←───────────┘\n",
    "\n",
    "    ingest → merge → commit\n",
    "```\n",
    "\n",
    "Ready for OS integration with Git-based persistent storage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hllset-manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
