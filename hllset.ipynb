{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HLLSet Immutable Batch Processing Tests\n",
    "\n",
    "This notebook demonstrates the immutable batch processing API for HLLSet.\n",
    "Key features:\n",
    "- All operations return new instances (immutable)\n",
    "- Batch processing is the primary mode\n",
    "- Multi-batch processing with optional parallelization\n",
    "- Union-based merging for accumulated results\n",
    "\n",
    "IMPORTANT: If you've made changes to hllset.py, restart the kernel before running.\n",
    "\"\"\"\n",
    "\n",
    "# NOTE: After code changes, restart kernel (Kernel -> Restart)\n",
    "from core.hllset import HLLSet, JULIA_AVAILABLE\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Julia Backend Available: {JULIA_AVAILABLE}\")\n",
    "print(\"Ready to test HLLSet batch processing!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Basic batch creation\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 1: Basic Batch Creation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create HLLSet from a single batch of tokens\n",
    "tokens = ['apple', 'banana', 'cherry', 'date', 'elderberry']\n",
    "hll1 = HLLSet.from_batch(tokens)\n",
    "\n",
    "print(f\"Created HLLSet from batch of {len(tokens)} tokens\")\n",
    "print(f\"HLLSet: {hll1}\")\n",
    "print(f\"Cardinality: {hll1.cardinality():.2f}\")\n",
    "print(f\"Name: {hll1.short_name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY: HLLSet Immutable Batch Processing API\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Key Features:\n",
    "✓ Fully immutable - all operations return new instances\n",
    "✓ Batch processing is the primary mode (from_batch)\n",
    "✓ Multi-batch processing with optional parallelization (from_batches)\n",
    "  NOTE: Parallel processing automatically disabled with Julia backend\n",
    "        due to thread-safety constraints (Julia is fast enough!)\n",
    "✓ Efficient merging via union operations\n",
    "✓ Content-addressed naming (deterministic hashes)\n",
    "✓ Set operations: union, intersect, diff\n",
    "✓ Similarity metrics: Jaccard, Cosine\n",
    "\n",
    "Recommended Patterns:\n",
    "1. Single batch:     HLLSet.from_batch(tokens)\n",
    "2. Multiple batches: HLLSet.from_batches(batches)  # Sequential with Julia\n",
    "                     HLLSet.from_batches(batches, parallel=True)  # Only without Julia\n",
    "3. Merging:          HLLSet.merge([hll1, hll2, ...])\n",
    "4. Accumulating:     hll1.union(hll2).union(hll3)\n",
    "\n",
    "Legacy Methods (for backward compatibility):\n",
    "- HLLSet.absorb(tokens) -> use from_batch() instead\n",
    "- HLLSet.add(base, tokens) -> use from_batch() + union() instead\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232492e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 9: Verify content addressing\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 9: Content-Addressed Naming\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Same tokens in different order should produce same HLLSet\n",
    "tokens_v1 = ['z', 'y', 'x', 'w', 'v']\n",
    "tokens_v2 = ['v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "hll_v1 = HLLSet.from_batch(tokens_v1)\n",
    "hll_v2 = HLLSet.from_batch(tokens_v2)\n",
    "\n",
    "print(f\"Tokens v1: {tokens_v1}\")\n",
    "print(f\"Tokens v2: {tokens_v2}\")\n",
    "print(f\"\\nHLL v1 name: {hll_v1.short_name}\")\n",
    "print(f\"HLL v2 name: {hll_v2.short_name}\")\n",
    "print(f\"Same content produces same name: {hll_v1.name == hll_v2.name}\")\n",
    "\n",
    "# Different tokens should produce different HLLSets\n",
    "tokens_v3 = ['a', 'b', 'c', 'd', 'e']\n",
    "hll_v3 = HLLSet.from_batch(tokens_v3)\n",
    "print(f\"\\nDifferent tokens: {tokens_v3}\")\n",
    "print(f\"HLL v3 name: {hll_v3.short_name}\")\n",
    "print(f\"Different content produces different name: {hll_v1.name != hll_v3.name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ef1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 8: Recommended usage pattern\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 8: Recommended Usage Pattern\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Pattern 1: Single batch\")\n",
    "print(\"-\" * 40)\n",
    "data_batch = ['user1', 'user2', 'user3', 'user1']  # duplicates OK\n",
    "hll = HLLSet.from_batch(data_batch)\n",
    "print(f\"Input: {data_batch}\")\n",
    "print(f\"Result: {hll}\")\n",
    "print(f\"Unique count: {hll.cardinality():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPattern 2: Multiple batches (with parallel flag)\")\n",
    "print(\"-\" * 40)\n",
    "print(\"NOTE: Parallel processing is automatically disabled when Julia backend\")\n",
    "print(\"      is available due to thread-safety. Julia sequential is still fast!\")\n",
    "print()\n",
    "incoming_batches = [\n",
    "    ['event_a_1', 'event_a_2', 'event_a_3'],\n",
    "    ['event_b_1', 'event_b_2', 'event_b_3'],\n",
    "    ['event_c_1', 'event_c_2', 'event_c_3'],\n",
    "]\n",
    "# parallel=True will be ignored if Julia backend is available (prevents crash)\n",
    "hll_combined = HLLSet.from_batches(incoming_batches, parallel=True)\n",
    "print(f\"Input: {len(incoming_batches)} batches\")\n",
    "print(f\"Result: {hll_combined}\")\n",
    "print(f\"Total unique: {hll_combined.cardinality():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nPattern 3: Accumulating over time\")\n",
    "print(\"-\" * 40)\n",
    "# Day 1\n",
    "day1_data = [f'user_{i}' for i in range(100)]\n",
    "hll_day1 = HLLSet.from_batch(day1_data)\n",
    "print(f\"Day 1: {hll_day1.cardinality():.0f} unique users\")\n",
    "\n",
    "# Day 2 (some overlap)\n",
    "day2_data = [f'user_{i}' for i in range(50, 150)]\n",
    "hll_day2 = HLLSet.from_batch(day2_data)\n",
    "print(f\"Day 2: {hll_day2.cardinality():.0f} unique users\")\n",
    "\n",
    "# Cumulative\n",
    "hll_total = hll_day1.union(hll_day2)\n",
    "print(f\"Total unique users across both days: {hll_total.cardinality():.0f}\")\n",
    "\n",
    "print(\"\\nPattern 4: Compare datasets\")\n",
    "print(\"-\" * 40)\n",
    "dataset_a = [f'item_{i}' for i in range(100)]\n",
    "dataset_b = [f'item_{i}' for i in range(50, 150)]\n",
    "\n",
    "hll_a = HLLSet.from_batch(dataset_a)\n",
    "hll_b = HLLSet.from_batch(dataset_b)\n",
    "\n",
    "similarity = hll_a.similarity(hll_b)\n",
    "cosine_sim = hll_a.cosine(hll_b)\n",
    "\n",
    "print(f\"Dataset A: {hll_a.cardinality():.0f} items\")\n",
    "print(f\"Dataset B: {hll_b.cardinality():.0f} items\")\n",
    "print(f\"Jaccard similarity: {similarity:.2%}\")\n",
    "print(f\"Cosine similarity: {cosine_sim:.2%}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 7: Large-scale batch processing\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 7: Large-Scale Batch Processing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Simulate streaming data with multiple batches\n",
    "num_batches = 10\n",
    "batch_size = 1000\n",
    "print(f\"Processing {num_batches} batches of {batch_size} tokens each\")\n",
    "\n",
    "# Generate batches\n",
    "large_batches = [\n",
    "    [f'stream_token_{batch_idx}_{i}' for i in range(batch_size)]\n",
    "    for batch_idx in range(num_batches)\n",
    "]\n",
    "\n",
    "# Sequential\n",
    "start = time.time()\n",
    "hll_seq = HLLSet.from_batches(large_batches, parallel=False)\n",
    "seq_time = time.time() - start\n",
    "print(f\"\\nSequential processing: {seq_time:.4f}s\")\n",
    "print(f\"Result: {hll_seq}\")\n",
    "\n",
    "# Parallel\n",
    "start = time.time()\n",
    "hll_par = HLLSet.from_batches(large_batches, parallel=True)\n",
    "par_time = time.time() - start\n",
    "print(f\"\\nParallel processing: {par_time:.4f}s\")\n",
    "print(f\"Result: {hll_par}\")\n",
    "print(f\"Speedup: {seq_time/par_time:.2f}x\")\n",
    "\n",
    "# Verify results\n",
    "print(f\"\\nResults match: {hll_seq.name == hll_par.name}\")\n",
    "print(f\"Total estimated unique: {hll_seq.cardinality():.0f}\")\n",
    "print(f\"Expected: {num_batches * batch_size} (all unique)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: Set operations remain immutable\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 6: Set Operations (Immutable)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create two HLLSets\n",
    "tokens_1 = [f'token_{i}' for i in range(50)]\n",
    "tokens_2 = [f'token_{i}' for i in range(25, 75)]  # overlaps 25-50\n",
    "\n",
    "hll1 = HLLSet.from_batch(tokens_1)\n",
    "hll2 = HLLSet.from_batch(tokens_2)\n",
    "\n",
    "print(f\"HLL1 cardinality: {hll1.cardinality():.2f}\")\n",
    "print(f\"HLL2 cardinality: {hll2.cardinality():.2f}\")\n",
    "\n",
    "# Union\n",
    "hll_union = hll1.union(hll2)\n",
    "print(f\"\\nUnion cardinality: {hll_union.cardinality():.2f}\")\n",
    "print(f\"Expected: ~75 (50 + 50 - 25 overlap)\")\n",
    "\n",
    "# Intersection\n",
    "hll_intersect = hll1.intersect(hll2)\n",
    "print(f\"\\nIntersection cardinality: {hll_intersect.cardinality():.2f}\")\n",
    "print(f\"Expected: ~25 (overlap)\")\n",
    "\n",
    "# Difference\n",
    "hll_diff = hll1.diff(hll2)\n",
    "print(f\"\\nDifference cardinality: {hll_diff.cardinality():.2f}\")\n",
    "print(f\"Expected: ~25 (tokens only in hll1)\")\n",
    "\n",
    "# Verify originals unchanged\n",
    "print(f\"\\nHLL1 still has original cardinality: {hll1.cardinality():.2f} == 50.0\")\n",
    "print(f\"HLL2 still has original cardinality: {hll2.cardinality():.2f} == 50.0\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b994bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Manual merge pattern (for overlapping batches)\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 5: Manual Merge Pattern (Overlapping Batches)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create overlapping batches\n",
    "batch_a = ['x', 'y', 'z', 'a', 'b']\n",
    "batch_b = ['a', 'b', 'c', 'd', 'e']  # overlaps with batch_a\n",
    "batch_c = ['m', 'n', 'o', 'p', 'q']  # no overlap\n",
    "\n",
    "print(f\"Batch A: {batch_a}\")\n",
    "print(f\"Batch B: {batch_b} (overlaps with A)\")\n",
    "print(f\"Batch C: {batch_c} (no overlap)\")\n",
    "\n",
    "# Process each batch independently\n",
    "hll_a = HLLSet.from_batch(batch_a)\n",
    "hll_b = HLLSet.from_batch(batch_b)\n",
    "hll_c = HLLSet.from_batch(batch_c)\n",
    "\n",
    "print(f\"\\nHLL A cardinality: {hll_a.cardinality():.2f}\")\n",
    "print(f\"HLL B cardinality: {hll_b.cardinality():.2f}\")\n",
    "print(f\"HLL C cardinality: {hll_c.cardinality():.2f}\")\n",
    "\n",
    "# Merge all\n",
    "hll_merged = HLLSet.merge([hll_a, hll_b, hll_c])\n",
    "print(f\"\\nMerged cardinality: {hll_merged.cardinality():.2f}\")\n",
    "print(f\"Expected unique: {len(set(batch_a + batch_b + batch_c))}\")\n",
    "\n",
    "# Manual union also works\n",
    "hll_union = hll_a.union(hll_b).union(hll_c)\n",
    "print(f\"Union cardinality: {hll_union.cardinality():.2f}\")\n",
    "print(f\"Merge and union produce same result: {hll_merged.name == hll_union.name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Multi-batch processing (sequential)\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 3: Multi-Batch Processing (Sequential)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create multiple batches\n",
    "batch1 = [f'token_batch1_{i}' for i in range(100)]\n",
    "batch2 = [f'token_batch2_{i}' for i in range(100)]\n",
    "batch3 = [f'token_batch3_{i}' for i in range(100)]\n",
    "batches = [batch1, batch2, batch3]\n",
    "\n",
    "print(f\"Processing {len(batches)} batches, each with 100 tokens\")\n",
    "\n",
    "# Sequential processing\n",
    "start = time.time()\n",
    "hll_sequential = HLLSet.from_batches(batches, parallel=False)\n",
    "sequential_time = time.time() - start\n",
    "\n",
    "print(f\"Sequential time: {sequential_time:.4f}s\")\n",
    "print(f\"Result: {hll_sequential}\")\n",
    "print(f\"Total estimated unique tokens: {hll_sequential.cardinality():.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08763402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Immutability verification\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 2: Immutability Verification\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create base HLLSet\n",
    "base_tokens = ['a', 'b', 'c']\n",
    "hll_base = HLLSet.from_batch(base_tokens)\n",
    "print(f\"Base HLLSet: {hll_base}\")\n",
    "print(f\"Base cardinality: {hll_base.cardinality():.2f}\")\n",
    "\n",
    "# Add more tokens - should return NEW instance\n",
    "new_tokens = ['d', 'e', 'f']\n",
    "hll_new = HLLSet.add(hll_base, new_tokens)\n",
    "print(f\"\\nAfter adding {new_tokens}:\")\n",
    "print(f\"New HLLSet: {hll_new}\")\n",
    "print(f\"New cardinality: {hll_new.cardinality():.2f}\")\n",
    "\n",
    "# Verify base is unchanged\n",
    "print(f\"\\nBase HLLSet after operation: {hll_base}\")\n",
    "print(f\"Base cardinality after operation: {hll_base.cardinality():.2f}\")\n",
    "print(f\"Base unchanged: {hll_base.cardinality() == 3.0}\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hllset-manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
