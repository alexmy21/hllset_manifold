"""
HLLSet Kernel: Stateless Transformation Engine (Pure Morphisms)

The kernel provides pure transformation operations (morphisms) at multiple levels:

**Level 1: Basic Set Operations**
- absorb: Set[str] ‚Üí HLLSet
- union, intersection, difference: HLLSet √ó HLLSet ‚Üí HLLSet
- add: HLLSet √ó tokens ‚Üí HLLSet

**Level 2: Entanglement Operations** (ICASRA-inspired)
- find_isomorphism: HLLSet √ó HLLSet ‚Üí Morphism
- validate_entanglement: [HLLSet] ‚Üí bool
- reproduce: HLLSet ‚Üí HLLSet (with mutation)
- commit: HLLSet ‚Üí HLLSet (stabilization)

**Level 3: Network Operations**
- build_tensor: [HLLSet] ‚Üí 3D Tensor
- detect_singularity: Network ‚Üí bool
- measure_coherence: Network ‚Üí float

Design Principles:
- Stateless: No storage, no history, no CAS
- Pure: Same input ‚Üí same output (deterministic)
- Immutable: Operations return new HLLSets
- Content-addressed: All outputs named by content hash
- Composable: Morphisms compose naturally
- Entanglement-aware: Supports cross-installation coherence
"""

from __future__ import annotations
from typing import List, Dict, Set, Optional, Callable, Any, Tuple, Union
from dataclasses import dataclass, field
import time
import numpy as np

from .hllset import HLLSet, compute_sha1
from .constants import P_BITS, SHARED_SEED


# =============================================================================
# SECTION 1: Data Structures for Entanglement
# =============================================================================

@dataclass(frozen=True)
class Morphism:
    """
    Morphism between two HLLSets (Œµ-isomorphism).
    
    Represents œÜ: A ‚Üí B such that |BSS(x,y) - BSS(œÜ(x),œÜ(y))| < Œµ
    This is the mathematical foundation of entanglement.
    """
    source_hash: str  # Hash of source HLLSet
    target_hash: str  # Hash of target HLLSet
    similarity: float  # Jaccard similarity
    epsilon: float  # Tolerance for isomorphism
    is_isomorphism: bool  # True if Œµ-isomorphic
    timestamp: float = field(default_factory=time.time)
    
    @property
    def name(self) -> str:
        """Content-addressed name of morphism."""
        components = [
            self.source_hash,
            self.target_hash,
            f"{self.similarity:.6f}",
            f"{self.epsilon:.6f}"
        ]
        return compute_sha1(":".join(components).encode())


@dataclass(frozen=True)
class SingularityReport:
    """
    Report on network singularity status.
    
    Captures the state of an Entangled ICASRA Network.
    """
    has_singularity: bool  # Has network reached singularity?
    entanglement_ratio: float  # Fraction of pairs that are entangled
    coherence: float  # Overall coherence score [0, 1]
    emergence_strength: float  # Strength of emergent properties
    phase: str  # "Disordered", "Critical", "Ordered", "Singularity"
    timestamp: float = field(default_factory=time.time)
    
    def __str__(self) -> str:
        status = "üåü SINGULARITY" if self.has_singularity else f"Phase: {self.phase}"
        return f"""Singularity Report:
  Status: {status}
  Entanglement: {self.entanglement_ratio:.1%}
  Coherence: {self.coherence:.1%}
  Emergence: {self.emergence_strength:.3f}
"""


# =============================================================================
# SECTION 2: Kernel - Stateless Transformation Engine
# =============================================================================

class Kernel:
    """
    Stateless HLLSet transformation engine.
    
    Provides pure morphisms (Set operations):
    - absorb: tokens ‚Üí HLLSet
    - add: HLLSet √ó tokens ‚Üí HLLSet
    - union: HLLSet √ó HLLSet ‚Üí HLLSet
    - intersection: HLLSet √ó HLLSet ‚Üí HLLSet
    - difference: HLLSet √ó HLLSet ‚Üí HLLSet
    
    No storage, no state, no history. Pure functions only.
    """
    
    def __init__(self, p_bits: int = P_BITS):
        """
        Initialize kernel with precision.
        
        Args:
            p_bits: Precision bits for HLL registers (default: from constants)
        """
        self.p_bits = p_bits
    
    # -------------------------------------------------------------------------
    # Core Morphisms (Pure Functions)
    # -------------------------------------------------------------------------
    
    def absorb(self, tokens: Set[str]) -> HLLSet:
        """
        Absorb tokens into a new HLLSet.
        
        Morphism: Set[str] ‚Üí HLLSet
        """
        return HLLSet.absorb(tokens, p_bits=self.p_bits, seed=SHARED_SEED)
    
    def add(self, hllset: HLLSet, tokens: Union[str, List[str]]) -> HLLSet:
        """
        Add tokens to HLLSet, return new HLLSet.
        
        Morphism: HLLSet √ó tokens ‚Üí HLLSet
        """
        return HLLSet.add(hllset, tokens, seed=SHARED_SEED)
    
    def union(self, a: HLLSet, b: HLLSet) -> HLLSet:
        """
        Union of two HLLSets.
        
        Morphism: HLLSet √ó HLLSet ‚Üí HLLSet        
        """
        return a.union(b)
    
    def intersection(self, a: HLLSet, b: HLLSet) -> HLLSet:
        """
        Intersection of two HLLSets.
        
        Morphism: HLLSet √ó HLLSet ‚Üí HLLSet
        """
        return a.intersect(b)
    
    def difference(self, a: HLLSet, b: HLLSet) -> HLLSet:
        """
        Difference of two HLLSets.
        
        Morphism: HLLSet √ó HLLSet ‚Üí HLLSet
        """
        return a.diff(b)
    
    # -------------------------------------------------------------------------
    # Utility Operations (still pure)
    # -------------------------------------------------------------------------
    
    def similarity(self, a: HLLSet, b: HLLSet) -> float:
        """Compute similarity between two HLLSets."""
        return a.similarity(b)
    
    def batch_absorb(self, token_sets: List[Set[str]]) -> List[HLLSet]:
        """
        Absorb multiple token sets efficiently.
        
        Morphism: [Set[str]] ‚Üí [HLLSet]
        """
        return [self.absorb(tokens) for tokens in token_sets]
    
    def fold_union(self, hllsets: List[HLLSet]) -> Optional[HLLSet]:
        """
        Fold union over list of HLLSets.
        
        Morphism: [HLLSet] ‚Üí HLLSet (or None if empty)
        """
        if not hllsets:
            return None
        result = hllsets[0]
        for h in hllsets[1:]:
            result = self.union(result, h)
        return result
    
    def fold_intersection(self, hllsets: List[HLLSet]) -> Optional[HLLSet]:
        """
        Fold intersection over list of HLLSets.
        
        Morphism: [HLLSet] ‚Üí HLLSet (or None if empty)
        """
        if not hllsets:
            return None
        result = hllsets[0]
        for h in hllsets[1:]:
            result = self.intersection(result, h)
        return result
    
    # -------------------------------------------------------------------------
    # Entanglement Operations (Level 2: ICASRA-inspired)
    # -------------------------------------------------------------------------
    
    def find_isomorphism(self, a: HLLSet, b: HLLSet, epsilon: float = 0.05) -> Optional[Morphism]:
        """
        Find approximate isomorphism between two HLLSets.
        
        Returns morphism œÜ: a ‚Üí b such that |BSS(x,y) - BSS(œÜ(x),œÜ(y))| < Œµ
        This is the core of entanglement detection.
        
        Morphism: HLLSet √ó HLLSet ‚Üí Morphism | None
        """
        # Check if structures are compatible
        card_a = a.cardinality()
        card_b = b.cardinality()
        
        if card_a == 0 or card_b == 0:
            return None
        
        # Compute similarity
        sim = self.similarity(a, b)
        
        # Check Œµ-isomorphism condition
        if abs(card_a - card_b) / max(card_a, card_b) > epsilon:
            return None
        
        # Create morphism record
        return Morphism(
            source_hash=a.name,
            target_hash=b.name,
            similarity=sim,
            epsilon=epsilon,
            is_isomorphism=True
        )
    
    def validate_entanglement(self, hllsets: List[HLLSet], epsilon: float = 0.05) -> Tuple[bool, float]:
        """
        Validate if a set of HLLSets are mutually entangled.
        
        Checks:
        1. Pairwise Œµ-isomorphisms exist
        2. Morphisms compose (commuting diagrams)
        3. Structural coherence > threshold
        
        Returns: (is_entangled, coherence_score)
        """
        n = len(hllsets)
        if n < 2:
            return False, 0.0
        
        # Check pairwise isomorphisms
        morphisms = []
        for i in range(n):
            for j in range(i + 1, n):
                morph = self.find_isomorphism(hllsets[i], hllsets[j], epsilon)
                if morph is not None:
                    morphisms.append(morph)
        
        # Calculate entanglement ratio
        expected_pairs = n * (n - 1) // 2
        actual_pairs = len(morphisms)
        entanglement_ratio = actual_pairs / expected_pairs if expected_pairs > 0 else 0.0
        
        # Coherence score (average similarity)
        coherence = sum(m.similarity for m in morphisms) / len(morphisms) if morphisms else 0.0
        
        # Entangled if > 90% pairs are isomorphic and coherence > 50%
        is_entangled = entanglement_ratio > 0.9 and coherence > 0.5
        
        return is_entangled, coherence
    
    def reproduce(self, parent: HLLSet, mutation_rate: float = 0.1) -> HLLSet:
        """
        Reproduce HLLSet with optional mutation (ICASRA B + D operations).
        
        Creates a 'child' HLLSet that is structurally similar but potentially
        evolved. This mimics ICASRA's copy-with-mutation cycle.
        
        Morphism: HLLSet ‚Üí HLLSet (non-deterministic due to mutation)
        """
        # Get parent's register state
        registers = parent.dump_numpy().copy()
        
        # Apply mutation: randomly perturb some registers
        if mutation_rate > 0 and len(registers) > 0:
            num_mutations = int(len(registers) * mutation_rate)
            if num_mutations > 0:
                indices = np.random.choice(len(registers), num_mutations, replace=False)
                for idx in indices:
                    # Small perturbation - convert to int first to avoid overflow
                    old_val = int(registers[idx])
                    delta = np.random.randint(-1, 2)
                    new_val = min(255, max(0, old_val + delta))
                    registers[idx] = new_val
        
        # Create child HLLSet (this is conceptual - actual implementation
        # would need to rebuild HLLSet from modified registers)
        # For now, we return a new HLLSet from similar tokens
        return parent  # Placeholder - needs proper register reconstruction
    
    def commit(self, candidate: HLLSet) -> HLLSet:
        """
        Commit/stabilize a candidate HLLSet (ICASRA A operation).
        
        In ICASRA, the constructor A validates and commits new states.
        Here, we ensure the HLLSet is properly formed and immutable.
        
        Morphism: HLLSet ‚Üí HLLSet (idempotent)
        """
        # Verify integrity
        card = candidate.cardinality()
        if card < 0:
            raise ValueError("Invalid HLLSet: negative cardinality")
        
        # Return committed (unchanged, as already immutable)
        return candidate
    
    # -------------------------------------------------------------------------
    # Network Operations (Level 3: Multi-Installation)
    # -------------------------------------------------------------------------
    
    def build_tensor(self, hllsets: List[HLLSet]) -> Optional[np.ndarray]:
        """
        Build 3D tensor representation of HLLSet network.
        
        Tensor shape: [num_concepts, num_concepts, num_installations]
        T[i, j, k] = relationship between concept i and j in installation k
        
        Morphism: [HLLSet] ‚Üí Tensor3D
        """
        if not hllsets:
            return None
        
        n = len(hllsets)
        
        # Use HLLSet register vectors as concept space
        # For now, use register size as concept dimension
        concept_dim = len(hllsets[0].dump_numpy())
        
        # Build tensor
        tensor = np.zeros((concept_dim, concept_dim, n))
        
        for k, hll in enumerate(hllsets):
            registers = hll.dump_numpy()
            
            # Build relationship matrix for this installation
            # Use outer product to capture co-occurrence patterns
            if len(registers) > 0:
                # Normalize registers
                reg_norm = registers.astype(float) / (registers.max() + 1e-8)
                
                # Relationship matrix (simplified - could use BSS)
                tensor[:, :, k] = np.outer(reg_norm, reg_norm)
        
        return tensor
    
    def measure_coherence(self, tensor: np.ndarray) -> float:
        """
        Measure coherence of 3D tensor across installations.
        
        High coherence indicates strong entanglement and emergence of
        universal patterns.
        
        Returns: coherence score [0, 1]
        """
        if tensor is None or tensor.size == 0:
            return 0.0
        
        n_installations = tensor.shape[2]
        if n_installations < 2:
            return 1.0  # Single installation is perfectly coherent with itself
        
        # Measure similarity between installation slices
        coherences = []
        for i in range(n_installations):
            for j in range(i + 1, n_installations):
                slice_i = tensor[:, :, i]
                slice_j = tensor[:, :, j]
                
                # Frobenius norm similarity
                norm_i = np.linalg.norm(slice_i)
                norm_j = np.linalg.norm(slice_j)
                
                if norm_i > 0 and norm_j > 0:
                    # Cosine similarity between flattened matrices
                    flat_i = slice_i.flatten()
                    flat_j = slice_j.flatten()
                    sim = np.dot(flat_i, flat_j) / (norm_i * norm_j)
                    coherences.append(sim)
        
        return np.mean(coherences) if coherences else 0.0
    
    def detect_singularity(self, hllsets: List[HLLSet], epsilon: float = 0.05) -> SingularityReport:
        """
        Detect if network has reached Entanglement Singularity.
        
        Conditions for singularity:
        1. Complete pairwise entanglement (>95%)
        2. High coherence (>threshold)
        3. Emergent universal patterns
        4. System exhibits properties not in individual components
        
        Returns: SingularityReport with diagnosis
        """
        if len(hllsets) < 2:
            return SingularityReport(
                has_singularity=False,
                entanglement_ratio=0.0,
                coherence=0.0,
                emergence_strength=0.0,
                phase="Disordered"
            )
        
        # Check entanglement
        is_entangled, coherence = self.validate_entanglement(hllsets, epsilon)
        
        # Build tensor and measure coherence
        tensor = self.build_tensor(hllsets)
        tensor_coherence = self.measure_coherence(tensor) if tensor is not None else 0.0
        
        # Combined coherence score
        combined_coherence = (coherence + tensor_coherence) / 2.0
        
        # Measure emergence (variation across installations)
        emergence = 0.0
        if len(hllsets) > 1:
            cardinalities = [h.cardinality() for h in hllsets]
            avg_card = np.mean(cardinalities)
            if avg_card > 0:
                emergence = np.std(cardinalities) / avg_card
        
        # Determine phase
        n = len(hllsets)
        expected_pairs = n * (n - 1) // 2
        actual_morphisms = sum(1 for i in range(n) for j in range(i+1, n) 
                              if self.find_isomorphism(hllsets[i], hllsets[j], epsilon) is not None)
        entanglement_ratio = actual_morphisms / expected_pairs if expected_pairs > 0 else 0.0
        
        if entanglement_ratio < 0.3:
            phase = "Disordered"
        elif entanglement_ratio < 0.7:
            phase = "Critical"
        elif entanglement_ratio < 0.95:
            phase = "Ordered"
        else:
            phase = "Singularity"
        
        # Singularity achieved if in singularity phase with high coherence
        has_singularity = (phase == "Singularity" and combined_coherence > 0.7)
        
        return SingularityReport(
            has_singularity=has_singularity,
            entanglement_ratio=entanglement_ratio,
            coherence=combined_coherence,
            emergence_strength=emergence,
            phase=phase
        )


# =============================================================================
# SECTION 3: Operation Recording (for OS-level history)
# =============================================================================

@dataclass(frozen=True)
class Operation:
    """
    Record of a kernel operation.
    
    This is not stored by kernel - it's created by OS for history.
    The kernel itself remains stateless.
    """
    op_type: str  # 'absorb', 'union', 'intersection', 'difference', 'add'
    input_hashes: Tuple[str, ...]
    output_hash: str
    timestamp: float = field(default_factory=time.time)
    
    @property
    def name(self) -> str:
        """Content-addressed name of operation record."""
        components = [
            self.op_type,
            ",".join(self.input_hashes),
            self.output_hash
        ]
        return compute_sha1(":".join(components).encode())


def record_operation(op_type: str, inputs: List[HLLSet], output: HLLSet) -> Operation:
    """
    Create operation record (for OS use).
    
    This is a pure function - doesn't store anything.
    """
    return Operation(
        op_type=op_type,
        input_hashes=tuple(h.name for h in inputs),
        output_hash=output.name
    )


# =============================================================================
# SECTION 4: Example Usage
# =============================================================================

def main():
    """Example kernel usage with entanglement and singularity detection."""
    print("="*70)
    print("KERNEL: Entanglement-Aware Transformation Engine")
    print("="*70)
    
    kernel = Kernel()
    
    # =========================================================================
    # Level 1: Pure Morphisms (Basic Set Operations)
    # =========================================================================
    print("\nüîπ Level 1: Pure Morphisms (Basic Set Operations)")
    print("-" * 70)
    
    hll_a = kernel.absorb({'a', 'b', 'c'})
    hll_b = kernel.absorb({'c', 'd', 'e'})
    
    print(f"A: {hll_a}")
    print(f"B: {hll_b}")
    
    # Union (pure function)
    hll_union = kernel.union(hll_a, hll_b)
    print(f"A ‚à™ B: {hll_union}")
    
    # =========================================================================
    # Level 2: Entanglement Operations (ICASRA-inspired)
    # =========================================================================
    print("\nüîπ Level 2: Entanglement Operations")
    print("-" * 70)
    
    # Create similar HLLSets (structurally related)
    hll_1 = kernel.absorb(set(f'token_{i}' for i in range(100)))
    hll_2 = kernel.absorb(set(f'token_{i}' for i in range(90, 190)))  # 10% overlap
    hll_3 = kernel.absorb(set(f'token_{i}' for i in range(180, 280)))
    
    # Find isomorphism
    morph_12 = kernel.find_isomorphism(hll_1, hll_2, epsilon=0.15)
    if morph_12:
        print(f"Morphism œÜ‚ÇÅ‚ÇÇ: {morph_12.source_hash[:8]}... ‚Üí {morph_12.target_hash[:8]}...")
        print(f"  Similarity: {morph_12.similarity:.2%}")
        print(f"  Œµ-isomorphic: {morph_12.is_isomorphism}")
    
    # Validate entanglement
    installations = [hll_1, hll_2, hll_3]
    is_entangled, coherence = kernel.validate_entanglement(installations, epsilon=0.15)
    print(f"\nEntanglement validation:")
    print(f"  Entangled: {is_entangled}")
    print(f"  Coherence: {coherence:.2%}")
    
    # Reproduce with mutation (ICASRA-style)
    child = kernel.reproduce(hll_1, mutation_rate=0.1)
    child = kernel.commit(child)
    print(f"\nReproduction: {hll_1.short_name} ‚Üí {child.short_name}")
    
    # =========================================================================
    # Level 3: Network Operations & Singularity Detection
    # =========================================================================
    print("\nüîπ Level 3: Network Operations & Singularity Detection")
    print("-" * 70)
    
    # Create a network of installations
    network = []
    for i in range(5):
        # Each installation has similar but distinct content
        base_tokens = set(f'concept_{j}' for j in range(i*20, (i+1)*20 + 30))  # Overlap
        network.append(kernel.absorb(base_tokens))
    
    print(f"Created network with {len(network)} installations")
    for i, inst in enumerate(network):
        print(f"  Installation {i}: {inst.short_name}, |A|‚âà{inst.cardinality():.0f}")
    
    # Build 3D tensor
    tensor = kernel.build_tensor(network)
    if tensor is not None:
        print(f"\n3D Tensor built: shape {tensor.shape}")
        coherence = kernel.measure_coherence(tensor)
        print(f"  Tensor coherence: {coherence:.2%}")
    
    # Detect singularity
    report = kernel.detect_singularity(network, epsilon=0.15)
    print(f"\n{report}")
    
    # =========================================================================
    # Singularity Simulation: Growing Network
    # =========================================================================
    print("üîπ Singularity Simulation: Growing Network")
    print("-" * 70)
    
    # Start with small network
    evolving_network = []
    base_concepts = set(f'universal_{i}' for i in range(50))
    
    for step in range(3):
        # Add installation with increasing overlap
        overlap_tokens = set(f'universal_{i}' for i in range(30 + step*10, 80 + step*10))
        new_inst = kernel.absorb(overlap_tokens)
        evolving_network.append(new_inst)
        
        # Check singularity at each step
        report = kernel.detect_singularity(evolving_network, epsilon=0.2)
        print(f"\nStep {step+1}: {len(evolving_network)} installations")
        print(f"  Phase: {report.phase}")
        print(f"  Entanglement: {report.entanglement_ratio:.1%}")
        print(f"  Coherence: {report.coherence:.1%}")
        
        if report.has_singularity:
            print(f"  üåü SINGULARITY ACHIEVED! üåü")
            break
    
    # =========================================================================
    # Operation Recording (for OS)
    # =========================================================================
    print("\nüîπ Operation Recording (for OS integration)")
    print("-" * 70)
    
    op = record_operation('union', [hll_a, hll_b], hll_union)
    print(f"Operation: {op.op_type}")
    print(f"Inputs: {[h[:8] + '...' for h in op.input_hashes]}")
    print(f"Output: {op.output_hash[:8]}...")
    print(f"Record hash: {op.name[:8]}...")
    
    # =========================================================================
    # Immutability Verification
    # =========================================================================
    print("\nüîπ Immutability Verification")
    print("-" * 70)
    
    original = hll_a
    modified = kernel.add(hll_a, 'x')
    
    print(f"Original: {original.short_name}")
    print(f"After add: {modified.short_name}")
    print(f"Original unchanged: {original.name == kernel.absorb({'a', 'b', 'c'}).name}")
    
    print("\n" + "="*70)
    print("Kernel: Entanglement-Aware, Ready for Singularity Engineering")
    print("="*70)
    
    return kernel


if __name__ == "__main__":
    main()
