{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67c4107",
   "metadata": {},
   "source": [
    "# Kernel Operations & Entanglement\n",
    "\n",
    "This notebook explores the Kernel as a stateless transformation engine and demonstrates entanglement concepts.\n",
    "\n",
    "**Key Concepts**:\n",
    "- Pure morphisms (stateless transformations)\n",
    "- Multi-level operations (basic sets, entanglement, network)\n",
    "- Isomorphism detection\n",
    "- Singularity and coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23fda4",
   "metadata": {},
   "source": [
    "## 1. Kernel: Stateless Transformations\n",
    "\n",
    "The Kernel provides pure operations - same input always produces same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60de70bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel is stateless:\n",
      "  - No storage\n",
      "  - No history\n",
      "  - No CAS (Content-Addressable Storage)\n",
      "  - Pure transformations only\n",
      "\n",
      "Kernel instance: <core.kernel.Kernel object at 0x7fe02964a060>\n"
     ]
    }
   ],
   "source": [
    "from core import Kernel, HLLSet\n",
    "\n",
    "# Create kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "print(\"Kernel is stateless:\")\n",
    "print(\"  - No storage\")\n",
    "print(\"  - No history\")\n",
    "print(\"  - No CAS (Content-Addressable Storage)\")\n",
    "print(\"  - Pure transformations only\")\n",
    "print(f\"\\nKernel instance: {kernel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1bfcaf",
   "metadata": {},
   "source": [
    "## 2. Level 1: Basic Set Operations\n",
    "\n",
    "Core morphisms for HLLSet manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a0d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Operations:\n",
      "\n",
      "A: HLLSet(983bcf39..., |A|≈4.0, backend=C/Cython)\n",
      "B: HLLSet(9b080fbe..., |A|≈4.0, backend=C/Cython)\n",
      "\n",
      "A ∪ B: HLLSet(eddbc507..., |A|≈5.0, backend=C/Cython)\n",
      "A ∩ B: HLLSet(ef34c2bc..., |A|≈3.0, backend=C/Cython)\n",
      "A - B: HLLSet(cede032c..., |A|≈2.0, backend=C/Cython)\n"
     ]
    }
   ],
   "source": [
    "# Absorb: tokens → HLLSet\n",
    "hll_a = kernel.absorb(['apple', 'banana', 'cherry'])\n",
    "hll_b = kernel.absorb(['banana', 'cherry', 'date'])\n",
    "\n",
    "print(\"Basic Operations:\\n\")\n",
    "print(f\"A: {hll_a}\")\n",
    "print(f\"B: {hll_b}\")\n",
    "\n",
    "# Union: A ∪ B\n",
    "union = kernel.union(hll_a, hll_b)\n",
    "print(f\"\\nA ∪ B: {union}\")\n",
    "\n",
    "# Intersection: A ∩ B\n",
    "intersection = kernel.intersection(hll_a, hll_b)\n",
    "print(f\"A ∩ B: {intersection}\")\n",
    "\n",
    "# Difference: A - B\n",
    "difference = kernel.difference(hll_a, hll_b)\n",
    "print(f\"A - B: {difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63c534",
   "metadata": {},
   "source": [
    "## 3. Similarity Measurements\n",
    "\n",
    "Compute similarity between HLLSets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c139b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity: 60.00%\n",
      "  |A ∩ B| / |A ∪ B|\n",
      "\n",
      "Cosine similarity: 75.00%\n",
      "\n",
      "X vs Y similarity: 40.00% (2 common / 4 total)\n"
     ]
    }
   ],
   "source": [
    "# Jaccard similarity\n",
    "jaccard = kernel.similarity(hll_a, hll_b)\n",
    "print(f\"Jaccard similarity: {jaccard:.2%}\")\n",
    "print(f\"  |A ∩ B| / |A ∪ B|\")\n",
    "\n",
    "# Cosine similarity (not in base Kernel, but in HLLSet)\n",
    "cosine = hll_a.cosine(hll_b)\n",
    "print(f\"\\nCosine similarity: {cosine:.2%}\")\n",
    "\n",
    "# Create more similar sets\n",
    "hll_x = kernel.absorb(['a', 'b', 'c'])\n",
    "hll_y = kernel.absorb(['a', 'b', 'd'])\n",
    "sim_xy = kernel.similarity(hll_x, hll_y)\n",
    "print(f\"\\nX vs Y similarity: {sim_xy:.2%} (2 common / 4 total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c15087c",
   "metadata": {},
   "source": [
    "## 4. Level 2: Fold Operations\n",
    "\n",
    "Aggregate multiple HLLSets via union or intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac86044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 HLLSets\n",
      "\n",
      "Union of all: HLLSet(f70d249e..., |A|≈8.0, backend=C/Cython)\n",
      "  Cardinality: 8.00\n",
      "  Expected: ~6 (a, b, c, d, e, f)\n",
      "\n",
      "Intersection of all: HLLSet(1ceaf73d..., |A|≈0.0, backend=C/Cython)\n",
      "  Cardinality: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Multiple HLLSets\n",
    "hll_list = [\n",
    "    kernel.absorb(['a', 'b', 'c']),\n",
    "    kernel.absorb(['b', 'c', 'd']),\n",
    "    kernel.absorb(['c', 'd', 'e']),\n",
    "    kernel.absorb(['d', 'e', 'f'])\n",
    "]\n",
    "\n",
    "print(f\"Created {len(hll_list)} HLLSets\\n\")\n",
    "\n",
    "# Fold union: combine all via union\n",
    "union_all = kernel.fold_union(hll_list)\n",
    "print(f\"Union of all: {union_all}\")\n",
    "print(f\"  Cardinality: {union_all.cardinality():.2f}\")\n",
    "print(f\"  Expected: ~6 (a, b, c, d, e, f)\")\n",
    "\n",
    "# Fold intersection: common to all\n",
    "intersection_all = kernel.fold_intersection(hll_list)\n",
    "print(f\"\\nIntersection of all: {intersection_all}\")\n",
    "print(f\"  Cardinality: {intersection_all.cardinality():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3295a9",
   "metadata": {},
   "source": [
    "## 5. Level 3: Isomorphism Detection\n",
    "\n",
    "Find approximate isomorphisms (ε-isomorphisms) between HLLSets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9483ae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation 1: fbd460b3..., |A|≈106\n",
      "Installation 2: f1abc9c2..., |A|≈109\n",
      "\n",
      "Found ε-isomorphism (ε=0.05):\n",
      "  Source: fbd460b3e13faf38184bce01a4d5b7b9481b9107\n",
      "  Target: f1abc9c253e7e8e5b4c8d1434f34f89901f23964\n",
      "  Similarity: 4.33%\n",
      "  Is isomorphic: True\n"
     ]
    }
   ],
   "source": [
    "# Create two installations (different data, similar structure)\n",
    "installation_1 = kernel.absorb([f'token_{i}' for i in range(100)])\n",
    "installation_2 = kernel.absorb([f'token_{i}' for i in range(95, 205)])\n",
    "\n",
    "print(f\"Installation 1: {installation_1.short_name}..., |A|≈{installation_1.cardinality():.0f}\")\n",
    "print(f\"Installation 2: {installation_2.short_name}..., |A|≈{installation_2.cardinality():.0f}\")\n",
    "\n",
    "# Find isomorphism\n",
    "epsilon = 0.05  # 5% tolerance\n",
    "morphism = kernel.find_isomorphism(installation_1, installation_2, epsilon=epsilon)\n",
    "\n",
    "if morphism:\n",
    "    print(f\"\\nFound ε-isomorphism (ε={epsilon}):\")\n",
    "    print(f\"  Source: {morphism.source_hash}\")\n",
    "    print(f\"  Target: {morphism.target_hash}\")\n",
    "    print(f\"  Similarity: {morphism.similarity:.2%}\")\n",
    "    print(f\"  Is isomorphic: {morphism.is_isomorphism}\")\n",
    "else:\n",
    "    print(f\"\\nNo ε-isomorphism found (similarity too low)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4439eda",
   "metadata": {},
   "source": [
    "## 6. Entanglement Validation\n",
    "\n",
    "Check if multiple HLLSets are mutually entangled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ffb243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 related installations\n",
      "  Installation 1: ca7b44e5..., |A|≈57\n",
      "  Installation 2: 4fbca95c..., |A|≈58\n",
      "  Installation 3: 6c460897..., |A|≈60\n",
      "\n",
      "Entanglement validation:\n",
      "  Entangled: True\n",
      "  Coherence: 69.93%\n",
      "\n",
      "  (High coherence means installations share common structure)\n"
     ]
    }
   ],
   "source": [
    "# Create related installations\n",
    "base_tokens = [f'common_{i}' for i in range(50)]\n",
    "\n",
    "installations = [\n",
    "    kernel.absorb(base_tokens + [f'unique_a_{i}' for i in range(10)]),\n",
    "    kernel.absorb(base_tokens + [f'unique_b_{i}' for i in range(10)]),\n",
    "    kernel.absorb(base_tokens + [f'unique_c_{i}' for i in range(10)])\n",
    "]\n",
    "\n",
    "print(f\"Created {len(installations)} related installations\")\n",
    "for i, inst in enumerate(installations, 1):\n",
    "    print(f\"  Installation {i}: {inst.short_name}..., |A|≈{inst.cardinality():.0f}\")\n",
    "\n",
    "# Validate entanglement\n",
    "is_entangled, coherence = kernel.validate_entanglement(installations, epsilon=0.05)\n",
    "\n",
    "print(f\"\\nEntanglement validation:\")\n",
    "print(f\"  Entangled: {is_entangled}\")\n",
    "print(f\"  Coherence: {coherence:.2%}\")\n",
    "print(f\"\\n  (High coherence means installations share common structure)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985f8fa",
   "metadata": {},
   "source": [
    "## 7. Reproduction with Mutation\n",
    "\n",
    "Create a reproduction of an HLLSet with slight mutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6971e942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1d01dd0c..., |A|≈52\n",
      "Reproduced: 1d01dd0c..., |A|≈52\n",
      "\n",
      "Similarity: 100.00%\n",
      "  (Mutation rate 10% affects similarity)\n"
     ]
    }
   ],
   "source": [
    "# Original HLLSet\n",
    "original = kernel.absorb([f'data_{i}' for i in range(50)])\n",
    "\n",
    "print(f\"Original: {original.short_name}..., |A|≈{original.cardinality():.0f}\")\n",
    "\n",
    "# Reproduce (with potential mutation)\n",
    "mutation_rate = 0.1  # 10% mutation\n",
    "reproduced = kernel.reproduce(original, mutation_rate=mutation_rate)\n",
    "\n",
    "print(f\"Reproduced: {reproduced.short_name}..., |A|≈{reproduced.cardinality():.0f}\")\n",
    "\n",
    "# Check similarity\n",
    "sim = kernel.similarity(original, reproduced)\n",
    "print(f\"\\nSimilarity: {sim:.2%}\")\n",
    "print(f\"  (Mutation rate {mutation_rate:.0%} affects similarity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e7a4e7",
   "metadata": {},
   "source": [
    "## 8. Commitment (Stabilization)\n",
    "\n",
    "Stabilize an HLLSet (in this system, HLLSets are already immutable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1aabf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncommitted: fd77d4b7...\n",
      "Committed: fd77d4b7...\n",
      "\n",
      "Same content: True\n",
      "  (HLLSets are already immutable, commit is identity operation)\n"
     ]
    }
   ],
   "source": [
    "# HLLSet to commit\n",
    "uncommitted = kernel.absorb(['pending', 'data', 'tokens'])\n",
    "\n",
    "print(f\"Uncommitted: {uncommitted.short_name}...\")\n",
    "\n",
    "# Commit (stabilize)\n",
    "committed = kernel.commit(uncommitted)\n",
    "\n",
    "print(f\"Committed: {committed.short_name}...\")\n",
    "print(f\"\\nSame content: {uncommitted.name == committed.name}\")\n",
    "print(\"  (HLLSets are already immutable, commit is identity operation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40ec47",
   "metadata": {},
   "source": [
    "## 9. Network Coherence\n",
    "\n",
    "Measure coherence across a network of HLLSets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77d777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created network with 5 installations\n",
      "\n",
      "Network coherence: 42.64%\n",
      "  Min similarity: 39.73%\n",
      "  Max similarity: 45.31%\n",
      "  Std deviation: 1.56%\n"
     ]
    }
   ],
   "source": [
    "# Create network of installations\n",
    "import numpy as np\n",
    "\n",
    "network = []\n",
    "num_installations = 5\n",
    "\n",
    "# Shared base + unique additions\n",
    "shared_base = [f'shared_{i}' for i in range(30)]\n",
    "\n",
    "for i in range(num_installations):\n",
    "    unique = [f'unique_{i}_{j}' for j in range(20)]\n",
    "    installation = kernel.absorb(shared_base + unique)\n",
    "    network.append(installation)\n",
    "\n",
    "print(f\"Created network with {len(network)} installations\")\n",
    "\n",
    "# Measure pairwise similarities\n",
    "similarities = []\n",
    "for i in range(len(network)):\n",
    "    for j in range(i+1, len(network)):\n",
    "        sim = kernel.similarity(network[i], network[j])\n",
    "        similarities.append(sim)\n",
    "\n",
    "avg_coherence = np.mean(similarities)\n",
    "print(f\"\\nNetwork coherence: {avg_coherence:.2%}\")\n",
    "print(f\"  Min similarity: {min(similarities):.2%}\")\n",
    "print(f\"  Max similarity: {max(similarities):.2%}\")\n",
    "print(f\"  Std deviation: {np.std(similarities):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defbff08",
   "metadata": {},
   "source": [
    "## 10. Composability\n",
    "\n",
    "Morphisms compose naturally - chaining operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c41144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result: HLLSet(a55e4d50..., |A|≈8.0, backend=C/Cython)\n",
      "Cardinality: 8.00\n",
      "\n",
      "Morphisms compose:\n",
      "  absorb → union → union\n",
      "  Each step returns new HLLSet\n",
      "  Pure functional composition\n"
     ]
    }
   ],
   "source": [
    "# Start with tokens\n",
    "tokens = ['initial', 'data', 'set']\n",
    "\n",
    "# Chain of transformations\n",
    "result = (\n",
    "    kernel.absorb(tokens)\n",
    "    .union(kernel.absorb(['additional', 'tokens']))\n",
    ")\n",
    "\n",
    "# Add more\n",
    "result = kernel.union(result, kernel.absorb(['even', 'more']))\n",
    "\n",
    "print(f\"Final result: {result}\")\n",
    "print(f\"Cardinality: {result.cardinality():.2f}\")\n",
    "print(f\"\\nMorphisms compose:\")\n",
    "print(\"  absorb → union → union\")\n",
    "print(\"  Each step returns new HLLSet\")\n",
    "print(\"  Pure functional composition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6ca169",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Kernel Capabilities**:\n",
    "\n",
    "**Level 1: Basic Operations**\n",
    "- absorb, union, intersection, difference\n",
    "- Pure, stateless transformations\n",
    "\n",
    "**Level 2: Entanglement**\n",
    "- find_isomorphism: Detect similar structures\n",
    "- validate_entanglement: Check mutual coherence\n",
    "- reproduce: Create variations\n",
    "- commit: Stabilize (identity in this system)\n",
    "\n",
    "**Level 3: Network**\n",
    "- Fold operations: Aggregate multiple HLLSets\n",
    "- Coherence measurement: Network similarity\n",
    "- Composability: Chain operations\n",
    "\n",
    "**Design Principles**:\n",
    "- Stateless: No storage, no history\n",
    "- Pure: Same input → same output\n",
    "- Immutable: Operations return new instances\n",
    "- Content-addressed: All outputs named by hash\n",
    "\n",
    "**Next**: See `05_manifold_os.ipynb` for OS-level orchestration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hllset-manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
