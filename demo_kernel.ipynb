{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLLSet Kernel Demo\n",
    "\n",
    "Interactive exploration of the Content-Addressed Immutable HLLSet Framework.\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "1. **Content-Addressed**: HLLSet name = SHA1(register contents)\n",
    "2. **Immutable**: Operations return NEW HLLSets, never modify\n",
    "3. **No Semantic Names**: Only external reality sources have names\n",
    "4. **Result is HLLSet**: All processing produces HLLSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Imported binding MainInclude.eval was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.eval into Main conflicts with an existing identifier; ignored.\n",
      "WARNING: Imported binding MainInclude.include was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.include into Main conflicts with an existing identifier; ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel initialized: DemoKernel\n"
     ]
    }
   ],
   "source": [
    "# Import the kernel\n",
    "from core.kernel import SystemKernel, HLLSet, CAS, compute_sha1\n",
    "\n",
    "# Create a kernel instance\n",
    "kernel = SystemKernel(\"DemoKernel\")\n",
    "print(f\"Kernel initialized: {kernel.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Absorb External Reality\n",
    "\n",
    "External reality sources are the only place with semantic names. Once absorbed, they become content-addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantum_field        → bfcfb568d70bbc13... (|A| ≈ 0.0)\n",
      "classical_field      → bfcfb568d70bbc13... (|A| ≈ 0.0)\n",
      "consciousness        → bfcfb568d70bbc13... (|A| ≈ 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Define external reality sources (semantic names allowed here only)\n",
    "reality_sources = {\n",
    "    \"quantum_field\": {\"superposition\", \"entanglement\", \"wave\", \"particle\"},\n",
    "    \"classical_field\": {\"position\", \"momentum\", \"trajectory\", \"deterministic\"},\n",
    "    \"consciousness\": {\"awareness\", \"experience\", \"reflection\", \"choice\"},\n",
    "}\n",
    "\n",
    "# Absorb into kernel\n",
    "hashes = {}\n",
    "for name, content in reality_sources.items():\n",
    "    h = kernel.absorb_reality(name, content)\n",
    "    hashes[name] = h\n",
    "    hllset = kernel.get(h)\n",
    "    print(f\"{name:20s} → {h[:16]}... (|A| ≈ {hllset.cardinality():.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Content-Addressed Naming\n",
    "\n",
    "The SHA1 hash is computed from the register contents, not assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying HLLSet details: 0.0\n",
      "HLLSet: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "Full SHA1: bfcfb568d70bbc13237f98b0c9e1505fe3d5a646\n",
      "Short name: bfcfb568\n",
      "Cardinality: 0.0\n",
      "\n",
      "Computed hash matches: True\n"
     ]
    }
   ],
   "source": [
    "# Get an HLLSet and verify its name\n",
    "hll = kernel.get(hashes[\"quantum_field\"])\n",
    "\n",
    "print(\"\\nVerifying HLLSet details:\", f\"{hll.cardinality():.1f}\")\n",
    "\n",
    "print(f\"HLLSet: {hll}\")\n",
    "print(f\"Full SHA1: {hll.name}\")\n",
    "print(f\"Short name: {hll.short_name}\")\n",
    "print(f\"Cardinality: {hll.cardinality():.1f}\")\n",
    "\n",
    "# Verify: re-compute SHA1 from register contents\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "registers = hll.get_register_vector()\n",
    "computed_hash = hashlib.sha1(registers.tobytes()).hexdigest()\n",
    "\n",
    "print(f\"\\nComputed hash matches: {computed_hash == hll.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demonstrate Immutability\n",
    "\n",
    "Adding tokens returns a NEW HLLSet with a NEW hash. The original is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: bfcfb568... |A|=0.0\n",
      "Modified: bfcfb568... |A|=0.0\n",
      "\n",
      "Original after 'add': bfcfb568... |A|=0.0\n",
      "Original unchanged: True\n"
     ]
    }
   ],
   "source": [
    "# Get original quantum field\n",
    "original_hash = hashes[\"quantum_field\"]\n",
    "original = kernel.get(original_hash)\n",
    "\n",
    "print(f\"Original: {original.short_name}... |A|={original.cardinality()}\")\n",
    "\n",
    "# Add tokens - returns NEW HLLSet\n",
    "new_hash = kernel.add_to(original_hash, [\"decoherence\", \"measurement\"])\n",
    "modified = kernel.get(new_hash)\n",
    "\n",
    "print(f\"Modified: {modified.short_name}... |A|={modified.cardinality()}\")\n",
    "\n",
    "# Original is unchanged!\n",
    "original_check = kernel.get(original_hash)\n",
    "print(f\"\\nOriginal after 'add': {original_check.short_name}... |A|={original_check.cardinality()}\")\n",
    "print(f\"Original unchanged: {original.name == original_check.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Operations\n",
    "\n",
    "Union, intersection, and difference all return NEW HLLSets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union: quantum ∪ classical\n",
      "  Result: bfcfb568... |A|=0.0\n",
      "  Expected: ~8 (4 + 4, but with possible overlap)\n",
      "\n",
      "Intersection: quantum ∩ classical\n",
      "  Result: bfcfb568... |A|=0.0\n",
      "  (Likely ~0 since quantum and classical are distinct)\n",
      "\n",
      "Triple Union: (quantum ∪ classical) ∪ consciousness\n",
      "  Result: bfcfb568... |A|=0.0\n"
     ]
    }
   ],
   "source": [
    "# Union: quantum ∪ classical\n",
    "union_hash = kernel.union(hashes[\"quantum_field\"], hashes[\"classical_field\"])\n",
    "union_hll = kernel.get(union_hash)\n",
    "\n",
    "print(f\"Union: quantum ∪ classical\")\n",
    "print(f\"  Result: {union_hll.short_name}... |A|={union_hll.cardinality()}\")\n",
    "print(f\"  Expected: ~8 (4 + 4, but with possible overlap)\")\n",
    "\n",
    "# Intersection: quantum ∩ classical\n",
    "inter_hash = kernel.intersection(hashes[\"quantum_field\"], hashes[\"classical_field\"])\n",
    "inter_hll = kernel.get(inter_hash)\n",
    "\n",
    "print(f\"\\nIntersection: quantum ∩ classical\")\n",
    "print(f\"  Result: {inter_hll.short_name}... |A|={inter_hll.cardinality()}\")\n",
    "print(f\"  (Likely ~0 since quantum and classical are distinct)\")\n",
    "\n",
    "# Triple union\n",
    "triple_hash = kernel.union(union_hash, hashes[\"consciousness\"])\n",
    "triple_hll = kernel.get(triple_hash)\n",
    "\n",
    "print(f\"\\nTriple Union: (quantum ∪ classical) ∪ consciousness\")\n",
    "print(f\"  Result: {triple_hll.short_name}... |A|={triple_hll.cardinality()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore the CAS\n",
    "\n",
    "Content-Addressed Store: simple hash → HLLSet mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAS contains 1 HLLSets:\n",
      "\n",
      " 1. bfcfb568d70bbc13237f... |A|=0.0\n"
     ]
    }
   ],
   "source": [
    "# Show all stored HLLSets\n",
    "print(f\"CAS contains {len(kernel.cas)} HLLSets:\\n\")\n",
    "\n",
    "for i, h in enumerate(kernel.cas.keys()):\n",
    "    hll = kernel.cas.get(h)\n",
    "    print(f\"{i+1:2d}. {h[:20]}... |A|={hll.cardinality():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BSS Morphisms\n",
    "\n",
    "Establish relationships between HLLSets using Bell State Similarity (τ-ρ duality).\n",
    "\n",
    "- **τ (inclusion tolerance)**: minimum required overlap\n",
    "- **ρ (exclusion intolerance)**: maximum allowed difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BSS Metrics (quantum → classical):\n",
      "  BSSτ (inclusion): 0.000 (need ≥ 0.5)\n",
      "  BSSρ (exclusion): 1.000 (need ≤ 0.3)\n",
      "  Morphism exists: False\n",
      "\n",
      "✗ Morphism not established (constraints not satisfied)\n",
      "\n",
      "Total morphisms in category: 0\n"
     ]
    }
   ],
   "source": [
    "from core.kernel import BSSMetrics\n",
    "\n",
    "# Compute BSS between quantum and classical\n",
    "q = kernel.get(hashes[\"quantum_field\"])\n",
    "c = kernel.get(hashes[\"classical_field\"])\n",
    "\n",
    "bss = BSSMetrics.compute(q, c, tau=0.5, rho=0.3)\n",
    "\n",
    "print(f\"BSS Metrics (quantum → classical):\")\n",
    "print(f\"  BSSτ (inclusion): {bss.bss_tau:.3f} (need ≥ {bss.tau})\")\n",
    "print(f\"  BSSρ (exclusion): {bss.bss_rho:.3f} (need ≤ {bss.rho})\")\n",
    "print(f\"  Morphism exists: {bss.is_satisfied}\")\n",
    "\n",
    "# Try to establish morphism\n",
    "morph_hash = kernel.establish_morphism(\n",
    "    hashes[\"quantum_field\"],\n",
    "    hashes[\"classical_field\"],\n",
    "    tau=0.9,   # Require 90% inclusion\n",
    "    rho=0.1    # Allow up to 10% exclusion\n",
    ")\n",
    "\n",
    "if morph_hash:\n",
    "    print(f\"\\n✓ Morphism established: {morph_hash[:16]}...\")\n",
    "else:\n",
    "    print(f\"\\n✗ Morphism not established (constraints not satisfied)\")\n",
    "\n",
    "print(f\"\\nTotal morphisms in category: {len(kernel.category.morphisms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Noether Conservation\n",
    "\n",
    "The conservation law: **|N| - |D| = 0**\n",
    "\n",
    "- **|N| (novelty)**: New information entering the system\n",
    "- **|D| (drift)**: Information leaving/changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noether Current (Φ): 0.000000\n",
      "Novelty |N|: 0.00\n",
      "Drift |D|: 0.00\n",
      "Conserved: True\n",
      "\n",
      "Creating more morphisms...\n",
      "Noether Φ after: 0.000000\n",
      "Morphism count: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Noether Current (Φ): {kernel.category.noether_phi:.6f}\")\n",
    "print(f\"Novelty |N|: {kernel.category.novelty:.2f}\")\n",
    "print(f\"Drift |D|: {kernel.category.drift:.2f}\")\n",
    "print(f\"Conserved: {kernel.category.is_conserved}\")\n",
    "\n",
    "# Creating morphisms adds novelty\n",
    "print(\"\\nCreating more morphisms...\")\n",
    "for i in range(3):\n",
    "    kernel.establish_morphism(\n",
    "        hashes[\"quantum_field\"],\n",
    "        hashes[\"consciousness\"],\n",
    "        tau=0.9, rho=0.1\n",
    "    )\n",
    "\n",
    "print(f\"Noether Φ after: {kernel.category.noether_phi:.6f}\")\n",
    "print(f\"Morphism count: {len(kernel.category.morphisms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Direct HLLSet Manipulation\n",
    "\n",
    "You can also work with HLLSets directly without the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "A: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "B: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "A ∪ B: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "A ∩ B: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "Similarity(A, B): 33.000\n"
     ]
    }
   ],
   "source": [
    "# Create HLLSets directly\n",
    "from core.kernel import HLL, P_BITS\n",
    "\n",
    "# Empty HLLSet\n",
    "empty = HLLSet(HLL(P_BITS=P_BITS))\n",
    "print(f\"Empty: {empty}\")\n",
    "\n",
    "# Add tokens\n",
    "hll_a = empty.add([\"a\", \"b\", \"c\"])\n",
    "hll_b = empty.add([\"b\", \"c\", \"d\"])\n",
    "\n",
    "print(f\"A: {hll_a}\")\n",
    "print(f\"B: {hll_b}\")\n",
    "\n",
    "# Operations\n",
    "hll_union = hll_a.union(hll_b)\n",
    "hll_inter = hll_a.intersection(hll_b)\n",
    "\n",
    "print(f\"\\nA ∪ B: {hll_union}\")\n",
    "print(f\"A ∩ B: {hll_inter}\")\n",
    "\n",
    "# Similarity\n",
    "sim = hll_a.similarity(hll_b)\n",
    "print(f\"\\nSimilarity(A, B): {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Experiment: Building Complex Structures\n",
    "\n",
    "Build up complex structures through composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building concept lattice...\n",
      "\n",
      "Base concepts:\n",
      "  matter       → bfcfb568d70bbc13... |A|=0.0\n",
      "  field        → bfcfb568d70bbc13... |A|=0.0\n",
      "  particle     → bfcfb568d70bbc13... |A|=0.0\n",
      "\n",
      "Composite concepts:\n",
      "  wave_particle      → bfcfb568d70bbc13... |A|=0.0\n",
      "  quantum_matter     → bfcfb568d70bbc13... |A|=0.0\n",
      "  classical_matter   → 0b6cfd6e39f96c5e... |A|=0.0\n",
      "\n",
      "CAS now contains 2 HLLSets\n"
     ]
    }
   ],
   "source": [
    "# Build a lattice-like structure\n",
    "print(\"Building concept lattice...\\n\")\n",
    "\n",
    "# Base concepts\n",
    "matter = kernel.absorb_reality(\"matter\", {\"mass\", \"energy\", \"spin\"})\n",
    "field = kernel.absorb_reality(\"field\", {\"wave\", \"oscillation\", \"energy\"})\n",
    "particle = kernel.absorb_reality(\"particle\", {\"mass\", \"position\", \"momentum\"})\n",
    "\n",
    "print(\"Base concepts:\")\n",
    "for name, h in [(\"matter\", matter), (\"field\", field), (\"particle\", particle)]:\n",
    "    hll = kernel.get(h)\n",
    "    print(f\"  {name:12s} → {h[:16]}... |A|={hll.cardinality():.1f}\")\n",
    "\n",
    "# Composite concepts\n",
    "wave_particle = kernel.union(field, particle)\n",
    "quantum_matter = kernel.intersection(matter, field)\n",
    "classical_matter = kernel.difference(matter, field)\n",
    "\n",
    "print(\"\\nComposite concepts:\")\n",
    "for name, h in [(\"wave_particle\", wave_particle), (\"quantum_matter\", quantum_matter), (\"classical_matter\", classical_matter)]:\n",
    "    hll = kernel.get(h)\n",
    "    print(f\"  {name:18s} → {h[:16]}... |A|={hll.cardinality():.1f}\")\n",
    "\n",
    "print(f\"\\nCAS now contains {len(kernel.cas)} HLLSets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Kernel Status\n",
    "\n",
    "Summary of the current kernel state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KERNEL STATUS\n",
      "============================================================\n",
      "name: DemoKernel\n",
      "cas_size: 2\n",
      "morphisms: 0\n",
      "noether_phi: 0.0\n",
      "conserved: True\n",
      "\n",
      "stats:\n",
      "    absorptions: 6\n",
      "    operations:\n",
      "      add: 1\n",
      "      union: 3\n",
      "      intersection: 2\n",
      "      difference: 1\n"
     ]
    }
   ],
   "source": [
    "status = kernel.status()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KERNEL STATUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for key, value in status.items():\n",
    "    if key == \"stats\":\n",
    "        print(f\"\\n{key}:\")\n",
    "        for k, v in value.items():\n",
    "            if k == \"operations\":\n",
    "                print(f\"    operations:\")\n",
    "                for op, count in v.items():\n",
    "                    print(f\"      {op}: {count}\")\n",
    "            else:\n",
    "                print(f\"    {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Content-addressed storage**: HLLSets are named by SHA1 of their contents\n",
    "2. **Immutability**: All operations return new HLLSets\n",
    "3. **CAS**: Simple hash → HLLSet mapping without graph traversal\n",
    "4. **BSS morphisms**: τ-ρ constrained relationships between HLLSets\n",
    "5. **Noether conservation**: |N| - |D| = 0 tracking\n",
    "\n",
    "Feel free to experiment with your own operations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hllset-manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
