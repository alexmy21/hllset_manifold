{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold OS Demo\n",
    "\n",
    "Interactive exploration of the Manifold Operating System.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```text\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                     MANIFOLD OS                             │\n",
    "│  ┌─────────────┐  ┌──────────────┐  ┌─────────────────┐     │\n",
    "│  │ Perceptrons │→ │   Pipeline   │→ │  Persistent     │     │\n",
    "│  │  (millions) │  │   (stages)   │  │  Storage (Git)  │     │\n",
    "│  └─────────────┘  └──────────────┘  └─────────────────┘     │\n",
    "│         ↓                ↓                    ↑             │\n",
    "│         └────────────────┴────────────────────┘             │\n",
    "│                        Evolution Loop                       │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "                              ↕\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                     KERNEL (stateless)                      │\n",
    "│  ┌─────────────┐  ┌──────────────┐  ┌─────────────────┐     │\n",
    "│  │   HLLSet    │  │     CAS      │  │   Operations    │     │\n",
    "│  │ (immutable) │  │ (undo/redo)  │  │ (union, etc.)   │     │\n",
    "│  └─────────────┘  └──────────────┘  └─────────────────┘     │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Key Principles\n",
    "\n",
    "1. **Kernel is Stateless**: Pure transformations, no persistent state\n",
    "2. **OS is Stateful**: Manages perceptrons, pipeline, evolution loop\n",
    "3. **Everything is HLLSet**: Collections of HLLSets are also HLLSets\n",
    "4. **Merge is Lossless**: Due to immutability and idempotence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Imported binding MainInclude.eval was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.eval into Main conflicts with an existing identifier; ignored.\n",
      "WARNING: Imported binding MainInclude.include was undeclared at import time during import to Main.\n",
      "WARNING: import of MainInclude.include into Main conflicts with an existing identifier; ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel and ManifoldOS imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import both Kernel and ManifoldOS\n",
    "from core.kernel import Kernel, HLLSet, compute_sha1\n",
    "from core.manifold_os import ManifoldOS, Perceptron, PipelineStage, OSState, EvolutionConfig\n",
    "\n",
    "print(\"Kernel and ManifoldOS imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Stateless Kernel\n",
    "\n",
    "The kernel provides pure transformation functions. It has no persistent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. KERNEL: Pure Transformations\n",
      "============================================================\n",
      "\n",
      "HLL A: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "HLL B: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "A ∪ B: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "A ∩ B: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "A \\ B: HLLSet(0b6cfd6e..., |A|≈0.0)\n",
      "\n",
      "Stored in CAS: 1 HLLSets\n",
      "Hash A: bfcfb568d70bbc13...\n",
      "Hash B: bfcfb568d70bbc13...\n",
      "Hash Union: bfcfb568d70bbc13...\n"
     ]
    }
   ],
   "source": [
    "# Create a kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"1. KERNEL: Pure Transformations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Absorb data into HLLSets\n",
    "hll_a = kernel.absorb({'superposition', 'entanglement', 'wave'})\n",
    "hll_b = kernel.absorb({'particle', 'position', 'momentum'})\n",
    "\n",
    "print(f\"\\nHLL A: {hll_a}\")\n",
    "print(f\"HLL B: {hll_b}\")\n",
    "\n",
    "# Pure transformations (always return new HLLSets)\n",
    "hll_union = kernel.union(hll_a, hll_b)\n",
    "hll_inter = kernel.intersection(hll_a, hll_b)\n",
    "hll_diff = kernel.difference(hll_a, hll_b)\n",
    "\n",
    "print(f\"\\nA ∪ B: {hll_union}\")\n",
    "print(f\"A ∩ B: {hll_inter}\")\n",
    "print(f\"A \\\\ B: {hll_diff}\")\n",
    "\n",
    "# Kernel CAS (temporary, for undo/redo)\n",
    "hash_a = kernel.store(hll_a)\n",
    "hash_b = kernel.store(hll_b)\n",
    "hash_union = kernel.store(hll_union)\n",
    "\n",
    "print(f\"\\nStored in CAS: {len(kernel.cas)} HLLSets\")\n",
    "print(f\"Hash A: {hash_a[:16]}...\")\n",
    "print(f\"Hash B: {hash_b[:16]}...\")\n",
    "print(f\"Hash Union: {hash_union[:16]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Undo/Redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation history: 1 operations\n",
      "Can undo: True\n",
      "Can redo: False\n",
      "\n",
      "Undo result: bfcfb568d70bbc13...\n",
      "Current op index: -1\n",
      "Redo result: bfcfb568d70bbc13...\n",
      "Current op index: 0\n"
     ]
    }
   ],
   "source": [
    "# Record operations for undo/redo\n",
    "kernel.record_operation('union', [hash_a, hash_b], hash_union)\n",
    "\n",
    "print(f\"Operation history: {len(kernel.operation_history)} operations\")\n",
    "print(f\"Can undo: {kernel.stats()['can_undo']}\")\n",
    "print(f\"Can redo: {kernel.stats()['can_redo']}\")\n",
    "\n",
    "# Undo\n",
    "undo_hash = kernel.undo()\n",
    "print(f\"\\nUndo result: {undo_hash[:16] if undo_hash else 'None'}...\")\n",
    "print(f\"Current op index: {kernel._current_op_index}\")\n",
    "\n",
    "# Redo\n",
    "redo_hash = kernel.redo()\n",
    "print(f\"Redo result: {redo_hash[:16] if redo_hash else 'None'}...\")\n",
    "print(f\"Current op index: {kernel._current_op_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Manifold OS - Perceptrons\n",
    "\n",
    "Perceptrons are the boundary between external reality and the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "2. MANIFOLD OS: Perceptrons\n",
      "============================================================\n",
      "\n",
      "Added 3 perceptrons:\n",
      "  visual_01: camera_main (visual)\n",
      "  audio_01: microphone_array (audio)\n",
      "  tactile_01: touch_sensor (tactile)\n"
     ]
    }
   ],
   "source": [
    "# Create ManifoldOS\n",
    "os = ManifoldOS()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"2. MANIFOLD OS: Perceptrons\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Add perceptrons (sensors)\n",
    "visual = os.add_perceptron(\"visual_01\", \"camera_main\", {\"type\": \"visual\", \"resolution\": \"1080p\"})\n",
    "audio = os.add_perceptron(\"audio_01\", \"microphone_array\", {\"type\": \"audio\", \"channels\": 4})\n",
    "tactile = os.add_perceptron(\"tactile_01\", \"touch_sensor\", {\"type\": \"tactile\", \"sensitivity\": \"high\"})\n",
    "\n",
    "print(f\"\\nAdded {len(os.perceptrons)} perceptrons:\")\n",
    "for pid, p in os.perceptrons.items():\n",
    "    print(f\"  {pid}: {p.source_name} ({p.metadata['type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absorb Data from Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absorbed data into HLLSets:\n",
      "  Visual:  HLLSet(bfcfb568..., |A|≈0.0)\n",
      "  Audio:   HLLSet(bfcfb568..., |A|≈0.0)\n",
      "  Tactile: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "Perceptron stats:\n",
      "  visual_01: 1 absorptions\n",
      "  audio_01: 1 absorptions\n",
      "  tactile_01: 1 absorptions\n"
     ]
    }
   ],
   "source": [
    "# Perceptrons absorb external reality\n",
    "visual_data = {\"red\", \"green\", \"blue\", \"yellow\", \"brightness\"}\n",
    "audio_data = {\"low_freq\", \"mid_freq\", \"high_freq\", \"amplitude\"}\n",
    "tactile_data = {\"pressure\", \"texture\", \"temperature\", \"vibration\"}\n",
    "\n",
    "# Absorb using the OS kernel\n",
    "visual_hll = visual.absorb(visual_data, os.kernel)\n",
    "audio_hll = audio.absorb(audio_data, os.kernel)\n",
    "tactile_hll = tactile.absorb(tactile_data, os.kernel)\n",
    "\n",
    "print(\"Absorbed data into HLLSets:\")\n",
    "print(f\"  Visual:  {visual_hll}\")\n",
    "print(f\"  Audio:   {audio_hll}\")\n",
    "print(f\"  Tactile: {tactile_hll}\")\n",
    "\n",
    "print(f\"\\nPerceptron stats:\")\n",
    "for pid, p in os.perceptrons.items():\n",
    "    print(f\"  {pid}: {p.absorption_count} absorptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Processing Pipeline\n",
    "\n",
    "The OS manages a processing pipeline using kernel transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "3. PROCESSING PIPELINE\n",
      "============================================================\n",
      "\n",
      "Pipeline stages (2):\n",
      "  1. sensory_merge: union\n",
      "  2. cross_modal: intersection\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"3. PROCESSING PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define pipeline stages\n",
    "stage1 = os.add_pipeline_stage(\"sensory_merge\", \"union\")\n",
    "stage2 = os.add_pipeline_stage(\"cross_modal\", \"intersection\")\n",
    "\n",
    "print(f\"\\nPipeline stages ({len(os.pipeline)}):\")\n",
    "for i, stage in enumerate(os.pipeline):\n",
    "    print(f\"  {i+1}. {stage.stage_id}: {stage.operation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Cycle\n",
    "\n",
    "One cycle: perceptrons → pipeline → new state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cycle...\n",
      "\n",
      "New state created:\n",
      "  State hash: ...\n",
      "  Root HLLSet: bfcfb568d70bbc13...\n",
      "  Parent: None...\n",
      "  Timestamp: 1769887319.9307985\n",
      "\n",
      "Root HLLSet: HLLSet(bfcfb568..., |A|≈0.0)\n"
     ]
    }
   ],
   "source": [
    "# Process one cycle\n",
    "perceptron_data = {\n",
    "    \"visual_01\": {\"color\", \"shape\", \"motion\"},\n",
    "    \"audio_01\": {\"pitch\", \"rhythm\", \"timbre\"},\n",
    "    \"tactile_01\": {\"pressure\", \"texture\", \"heat\"},\n",
    "}\n",
    "\n",
    "print(\"Processing cycle...\")\n",
    "state = os.process_cycle(perceptron_data)\n",
    "\n",
    "print(f\"\\nNew state created:\")\n",
    "print(f\"  State hash: {state.state_hash[:16]}...\")\n",
    "print(f\"  Root HLLSet: {state.root_hllset_hash[:16]}...\")\n",
    "print(f\"  Parent: {state.parent_state[:16] if state.parent_state else 'None'}...\")\n",
    "print(f\"  Timestamp: {state.timestamp}\")\n",
    "\n",
    "# Get root HLLSet\n",
    "root = os.get_root()\n",
    "print(f\"\\nRoot HLLSet: {root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Processing Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 3 additional cycles...\n",
      "\n",
      "Cycle 2: root = bfcfb568..., |A|=0.0\n",
      "Cycle 3: root = bfcfb568..., |A|=0.0\n",
      "Cycle 4: root = bfcfb568..., |A|=0.0\n",
      "\n",
      "Total processing cycles: 4\n",
      "Kernel CAS size: 1\n"
     ]
    }
   ],
   "source": [
    "# Run multiple cycles\n",
    "cycles = [\n",
    "    {\"visual_01\": {\"edge\", \"corner\"}, \"audio_01\": {\"beat\", \"tone\"}},\n",
    "    {\"visual_01\": {\"texture\", \"pattern\"}, \"tactile_01\": {\"smooth\", \"rough\"}},\n",
    "    {\"audio_01\": {\"harmony\", \"melody\"}, \"tactile_01\": {\"warm\", \"cold\"}},\n",
    "]\n",
    "\n",
    "print(f\"Running {len(cycles)} additional cycles...\\n\")\n",
    "\n",
    "for i, data in enumerate(cycles, 2):\n",
    "    state = os.process_cycle(data)\n",
    "    root = os.get_root()\n",
    "    print(f\"Cycle {i}: root = {root.short_name}..., |A|={root.cardinality():.1f}\")\n",
    "\n",
    "print(f\"\\nTotal processing cycles: {os.processing_cycles}\")\n",
    "print(f\"Kernel CAS size: {len(os.kernel.cas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Persistence (Git-like)\n",
    "\n",
    "The OS manages persistent storage. Kernel CAS is temporary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "4. PERSISTENT STORAGE\n",
      "============================================================\n",
      "\n",
      "Committing state...\n",
      "Committed: 8875280f9a8bf9db...\n",
      "Persistent states: 1\n",
      "Kernel CAS after commit: 0 (cleared)\n",
      "Kernel operations: 0 (cleared)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"4. PERSISTENT STORAGE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# Ensure we have a state to commit (run a cycle if needed)\n",
    "if not os.current_state:\n",
    "    print(\"No current state, running a quick processing cycle...\")\n",
    "    os.process_cycle({\"visual_01\": {\"init\"}})\n",
    "\n",
    "# Commit current state\n",
    "print(\"\\nCommitting state...\")\n",
    "commit_hash = os.commit(\"After 4 processing cycles\")\n",
    "\n",
    "print(f\"Committed: {commit_hash[:16]}...\")\n",
    "print(f\"Persistent states: {len(os.store.states)}\")\n",
    "\n",
    "# After commit, kernel CAS can be cleared (undo/redo no longer needed)\n",
    "print(f\"Kernel CAS after commit: {len(os.kernel.cas)} (cleared)\")\n",
    "print(f\"Kernel operations: {len(os.kernel.operation_history)} (cleared)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second commit: f211f2b7650cc234...\n",
      "\n",
      "State history (2 states):\n",
      "  1. 8875280f9a8bf9db... (parent: None...)\n",
      "  2. f211f2b7650cc234... (parent: 8875280f9a8bf9db...)\n"
     ]
    }
   ],
   "source": [
    "# Do more processing and commit again\n",
    "os.process_cycle({\"visual_01\": {\"final\"}})\n",
    "commit2 = os.commit(\"Final processing\")\n",
    "\n",
    "print(f\"Second commit: {commit2[:16]}...\\n\")\n",
    "\n",
    "# View history\n",
    "history = os.get_history()\n",
    "print(f\"State history ({len(history)} states):\")\n",
    "for i, state in enumerate(history):\n",
    "    parent = state.parent_state[:16] if state.parent_state else \"None\"\n",
    "    print(f\"  {i+1}. {state.state_hash[:16]}... (parent: {parent}...)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkout Previous State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out first commit...\n",
      "Restored: 8875280f9a8bf9db...\n",
      "Root at that state: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "Back to latest: HLLSet(bfcfb568..., |A|≈0.0)\n"
     ]
    }
   ],
   "source": [
    "# Checkout first commit\n",
    "print(\"Checking out first commit...\")\n",
    "first_state = os.checkout(commit_hash)\n",
    "\n",
    "if first_state:\n",
    "    print(f\"Restored: {first_state.state_hash[:16]}...\")\n",
    "    root = os.get_root()\n",
    "    print(f\"Root at that state: {root}\")\n",
    "\n",
    "# Go back to latest\n",
    "os.checkout(commit2)\n",
    "print(f\"\\nBack to latest: {os.get_root()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Evolution Loop\n",
    "\n",
    "The OS can run an autonomous evolution loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "5. EVOLUTION LOOP\n",
      "============================================================\n",
      "Running evolution (5 iterations)...\n",
      "\n",
      "Evolution complete:\n",
      "  Iterations: 5\n",
      "  Convergence history: [0.0, 0.0, 0.0, 0.0]\n",
      "  Final state: ...\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"5. EVOLUTION LOOP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create fresh OS for evolution demo\n",
    "evo_os = ManifoldOS()\n",
    "\n",
    "# Add perceptrons\n",
    "evo_os.add_perceptron(\"p1\", \"source_1\")\n",
    "evo_os.add_perceptron(\"p2\", \"source_2\")\n",
    "\n",
    "# Add pipeline\n",
    "evo_os.add_pipeline_stage(\"merge\", \"union\")\n",
    "\n",
    "# Configure evolution\n",
    "evo_os.evolution.config.max_iterations = 5\n",
    "evo_os.evolution.config.convergence_threshold = 0.99\n",
    "\n",
    "print(\"Running evolution (5 iterations)...\")\n",
    "\n",
    "# Note: In real scenario, perceptrons would have continuous data\n",
    "# Here we simulate by running the evolution\n",
    "final_state = evo_os.run_evolution(max_iterations=5)\n",
    "\n",
    "print(f\"\\nEvolution complete:\")\n",
    "print(f\"  Iterations: {evo_os.evolution.iteration_count}\")\n",
    "print(f\"  Convergence history: {evo_os.evolution.convergence_history}\")\n",
    "print(f\"  Final state: {final_state.state_hash[:16]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Everything is HLLSet\n",
    "\n",
    "Collections of HLLSets are also HLLSets (via union)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "6. EVERYTHING IS HLLSET\n",
      "============================================================\n",
      "Individual HLLSets:\n",
      "  h1: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "  h2: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "  h3: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "Collection (h1 ∪ h2 ∪ h3): HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "Stored 4 HLLSets in persistent storage\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"6. EVERYTHING IS HLLSET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create multiple HLLSets\n",
    "h1 = os.kernel.absorb({\"a\", \"b\", \"c\"})\n",
    "h2 = os.kernel.absorb({\"d\", \"e\", \"f\"})\n",
    "h3 = os.kernel.absorb({\"g\", \"h\", \"i\"})\n",
    "\n",
    "print(\"Individual HLLSets:\")\n",
    "print(f\"  h1: {h1}\")\n",
    "print(f\"  h2: {h2}\")\n",
    "print(f\"  h3: {h3}\")\n",
    "\n",
    "# Collection is also an HLLSet (via union)\n",
    "collection = os.kernel.union(os.kernel.union(h1, h2), h3)\n",
    "print(f\"\\nCollection (h1 ∪ h2 ∪ h3): {collection}\")\n",
    "\n",
    "# Store in OS\n",
    "os.store.store_hllset(h1)\n",
    "os.store.store_hllset(h2)\n",
    "os.store.store_hllset(h3)\n",
    "os.store.store_hllset(collection)\n",
    "\n",
    "print(f\"\\nStored {len([h1, h2, h3, collection])} HLLSets in persistent storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Kernel CAS into OS Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel CAS has 1 HLLSets\n",
      "\n",
      "Merged root: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "Kernel CAS preserved: 1 HLLSets still in kernel\n",
      "Structure preserved: All HLLSets individually addressable\n"
     ]
    }
   ],
   "source": [
    "# Fill kernel CAS with some data\n",
    "for i in range(5):\n",
    "    h = os.kernel.absorb({f\"item_{i}_{j}\" for j in range(3)})\n",
    "    os.kernel.store(h)\n",
    "\n",
    "print(f\"Kernel CAS has {len(os.kernel.cas)} HLLSets\")\n",
    "\n",
    "# Merge into OS storage\n",
    "merged_root = os.store.merge_kernel_cas(os.kernel)\n",
    "\n",
    "print(f\"\\nMerged root: {merged_root}\")\n",
    "print(f\"Kernel CAS preserved: {len(os.kernel.cas)} HLLSets still in kernel\")\n",
    "print(f\"Structure preserved: All HLLSets individually addressable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Similarity Queries\n",
    "\n",
    "Find HLLSets similar to a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "7. SIMILARITY QUERIES\n",
      "============================================================\n",
      "Query HLLSet: HLLSet(bfcfb568..., |A|≈0.0)\n",
      "\n",
      "Similar HLLSets (threshold=0.3):\n",
      "  bfcfb568d70bbc13... sim=67.000, |A|=0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"7. SIMILARITY QUERIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create query HLLSet\n",
    "query = os.kernel.absorb({\"a\", \"b\", \"x\", \"y\"})\n",
    "\n",
    "# Store some HLLSets to query against\n",
    "os.kernel.store(os.kernel.absorb({\"a\", \"b\", \"c\"}))\n",
    "os.kernel.store(os.kernel.absorb({\"x\", \"y\", \"z\"}))\n",
    "os.kernel.store(os.kernel.absorb({\"a\", \"b\", \"x\"}))\n",
    "\n",
    "# Query for similar HLLSets\n",
    "similar = os.query_similar(query, threshold=0.3)\n",
    "\n",
    "print(f\"Query HLLSet: {query}\")\n",
    "print(f\"\\nSimilar HLLSets (threshold=0.3):\")\n",
    "for h, sim in similar:\n",
    "    hll = os.kernel.retrieve(h)\n",
    "    print(f\"  {h[:16]}... sim={sim:.3f}, |A|={hll.cardinality():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Complete Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "8. FINAL STATISTICS\n",
      "============================================================\n",
      "\n",
      "OS Stats:\n",
      "  runtime: 0.9173245429992676\n",
      "  processing_cycles: 5\n",
      "  perceptrons: 3\n",
      "  pipeline_stages: 2\n",
      "  kernel_stats:\n",
      "    cas_size: 1\n",
      "    operation_count: 0\n",
      "    current_op_index: -1\n",
      "    can_undo: False\n",
      "    can_redo: False\n",
      "  persistent_states: 2\n",
      "  current_state: f211f2b7650cc234\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"8. FINAL STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stats = os.stats()\n",
    "\n",
    "print(\"\\nOS Stats:\")\n",
    "for key, value in stats.items():\n",
    "    if key == \"kernel_stats\":\n",
    "        print(f\"  {key}:\")\n",
    "        for k, v in value.items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Stateless Kernel**: Pure HLLSet transformations, CAS for undo/redo\n",
    "2. **Perceptrons**: Boundary with external reality\n",
    "3. **Processing Pipeline**: OS-managed stages using kernel\n",
    "4. **Persistence**: Git-like commit/checkout of OS state\n",
    "5. **Evolution Loop**: Self-generating processing cycles\n",
    "6. **Everything is HLLSet**: Collections merge via union\n",
    "7. **Lossless Merge**: Due to immutability and idempotence\n",
    "\n",
    "**Architecture**: Kernel (stateless) ↔ Manifold OS (stateful) ↔ Persistent Storage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hllset-manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
