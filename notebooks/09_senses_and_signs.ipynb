{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced46d3f",
   "metadata": {},
   "source": [
    "# Senses and Signs: Saussure Duality in HRT\n",
    "\n",
    "This notebook demonstrates **dual-channel perception** using HRT lattices, based on Ferdinand de Saussure's concept of signified (object) and signifier (sign).\n",
    "\n",
    "## Conceptual Framework\n",
    "\n",
    "**Reality → Two Perception Channels:**\n",
    "\n",
    "1. **Sensory Channel (W_sensory)**: Direct perceptual experience\n",
    "   - Vision, audition, touch, etc.\n",
    "   - Grounded in physical reality\n",
    "   - BasicHLLSets represent perceptual features\n",
    "\n",
    "2. **Language Channel (W_language)**: Symbolic representation\n",
    "   - Words, phrases, sentences\n",
    "   - Abstract and conventional\n",
    "   - BasicHLLSets represent semantic features\n",
    "\n",
    "**Entanglement = Meaning:**\n",
    "- The connection between reality and language is **entanglement** between lattices\n",
    "- Measured by **ε-isomorphism probability**\n",
    "- High ε-isomorphism → Strong semantic grounding\n",
    "- Low ε-isomorphism → Abstract concepts\n",
    "\n",
    "**References:**\n",
    "- **DOCS/SENSES_SIGNS_SAUSSURE.md**: Theoretical framework\n",
    "- **DOCS/EPSILON_ISOMORPHISM.md**: ε-isomorphism definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ed31be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Framework loaded\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/alexmy/SGS/SGS_lib/hllset_manifold')\n",
    "\n",
    "from core.hrt import (\n",
    "    HRTConfig, HRT,\n",
    "    BasicHLLSet, HLLSetLattice\n",
    ")\n",
    "from core.kernel import Kernel\n",
    "from core.hllset import HLLSet\n",
    "\n",
    "kernel = Kernel()\n",
    "print(\"✓ Framework loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108daeb5",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "We'll use moderate thresholds:\n",
    "- **τ = 0.6**: Require 60% inclusion for morphism\n",
    "- **ρ = 0.3**: Allow at most 30% exclusion\n",
    "- **ε = 0.15**: Tolerance for ε-isomorphism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b7cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  τ = 0.6 (inclusion threshold)\n",
      "  ρ = 0.3 (exclusion threshold)\n",
      "  ε = 0.15 (ε-isomorphism tolerance)\n",
      "  Dimension: 4098\n"
     ]
    }
   ],
   "source": [
    "config = HRTConfig(\n",
    "    p_bits=8,\n",
    "    h_bits=16,\n",
    "    tau=0.6,\n",
    "    rho=0.3,\n",
    "    epsilon=0.15\n",
    ")\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  τ = {config.tau} (inclusion threshold)\")\n",
    "print(f\"  ρ = {config.rho} (exclusion threshold)\")\n",
    "print(f\"  ε = {config.epsilon} (ε-isomorphism tolerance)\")\n",
    "print(f\"  Dimension: {config.dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688983b",
   "metadata": {},
   "source": [
    "## Example 1: Grounded Concepts\n",
    "\n",
    "**Concept: \"Red Apple\"**\n",
    "\n",
    "- **Sensory representation**: Visual features (color, shape, texture)\n",
    "- **Language representation**: Words and semantic associations\n",
    "\n",
    "We expect **high ε-isomorphism** (strong grounding) for concrete objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d99531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Red Apple\n",
      "\n",
      "Sensory features:\n",
      "  red: ['wavelength_630nm', 'color_red']...\n",
      "  round: ['circular_shape', 'sphere']...\n",
      "  smooth: ['smooth_texture', 'glossy']...\n",
      "  apple: ['fruit_shape', 'stem_top']...\n",
      "\n",
      "Language features:\n",
      "  red: ['color_descriptor', 'warm_color']...\n",
      "  round: ['shape_descriptor', 'circular']...\n",
      "  smooth: ['texture_descriptor', 'surface_property']...\n",
      "  apple: ['fruit_category', 'edible']...\n"
     ]
    }
   ],
   "source": [
    "# Sensory channel: Visual perceptual features\n",
    "sensory_features = {\n",
    "    'red': ['wavelength_630nm', 'color_red', 'bright', 'saturated'],\n",
    "    'round': ['circular_shape', 'sphere', 'curved_surface', 'no_edges'],\n",
    "    'smooth': ['smooth_texture', 'glossy', 'reflective', 'skin'],\n",
    "    'apple': ['fruit_shape', 'stem_top', 'depression_bottom', 'size_hand']\n",
    "}\n",
    "\n",
    "# Language channel: Semantic/linguistic features\n",
    "language_features = {\n",
    "    'red': ['color_descriptor', 'warm_color', 'primary_color', 'spectrum'],\n",
    "    'round': ['shape_descriptor', 'circular', 'spherical', 'geometry'],\n",
    "    'smooth': ['texture_descriptor', 'surface_property', 'not_rough'],\n",
    "    'apple': ['fruit_category', 'edible', 'grows_trees', 'has_seeds']\n",
    "}\n",
    "\n",
    "print(\"Concept: Red Apple\")\n",
    "print(\"\\nSensory features:\")\n",
    "for label, features in sensory_features.items():\n",
    "    print(f\"  {label}: {features[:2]}...\")\n",
    "\n",
    "print(\"\\nLanguage features:\")\n",
    "for label, features in language_features.items():\n",
    "    print(f\"  {label}: {features[:2]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83bd0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 4 sensory BasicHLLSets\n",
      "Created 4 language BasicHLLSets\n"
     ]
    }
   ],
   "source": [
    "# Create sensory lattice (simplified - using lists instead of full HLLSetLattice)\n",
    "sensory_basics = []\n",
    "for idx, (label, features) in enumerate(sensory_features.items()):\n",
    "    hllset = kernel.absorb(features)\n",
    "    basic = BasicHLLSet(index=idx, is_row=True, hllset=hllset, config=config)\n",
    "    sensory_basics.append((label, basic))\n",
    "\n",
    "# Create language lattice\n",
    "language_basics = []\n",
    "for idx, (label, features) in enumerate(language_features.items()):\n",
    "    hllset = kernel.absorb(features)\n",
    "    basic = BasicHLLSet(index=idx, is_row=True, hllset=hllset, config=config)\n",
    "    language_basics.append((label, basic))\n",
    "\n",
    "print(f\"\\nCreated {len(sensory_basics)} sensory BasicHLLSets\")\n",
    "print(f\"Created {len(language_basics)} language BasicHLLSets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbbfeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "IMPORTANT: Cross-Modal BSS is MEANINGLESS\n",
      "======================================================================\n",
      "\n",
      "Sensory and language lattices use DIFFERENT vocabularies:\n",
      "  - Sensory: ['wavelength_630nm', 'bright', 'saturated']\n",
      "  - Language: ['color_descriptor', 'warm_color', 'primary_color']\n",
      "\n",
      "These HLLSets have ZERO intersection (disjoint)!\n",
      "  → BSS_τ = |A ∩ B| / |B| = 0 / |B| = 0\n",
      "  → BSS_ρ = |A \\ B| / |B| = |A| / |B| ≈ 1\n",
      "\n",
      "Demonstration:\n",
      "  red: BSS_τ = 0.000, BSS_ρ = 0.800\n",
      "  round: BSS_τ = 0.000, BSS_ρ = 1.000\n",
      "\n",
      "======================================================================\n",
      "CORRECT APPROACH: Compare by STRUCTURE, not content\n",
      "======================================================================\n",
      "\n",
      "We need to compare graph topology (node degrees, morphisms)\n",
      "not node content (HLLSet intersection).\n",
      "\n",
      "See full lattice comparison below for structural matching.\n"
     ]
    }
   ],
   "source": [
    "# KEY INSIGHT: Cross-modal lattices have DISJOINT token spaces!\n",
    "# Sensory tokens ∩ Language tokens = ∅\n",
    "# Therefore: BSS_τ = 0, BSS_ρ = 1 ALWAYS (meaningless for cross-modal)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMPORTANT: Cross-Modal BSS is MEANINGLESS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nSensory and language lattices use DIFFERENT vocabularies:\")\n",
    "print(\"  - Sensory: ['wavelength_630nm', 'bright', 'saturated']\")\n",
    "print(\"  - Language: ['color_descriptor', 'warm_color', 'primary_color']\")\n",
    "print(\"\\nThese HLLSets have ZERO intersection (disjoint)!\")\n",
    "print(\"  → BSS_τ = |A ∩ B| / |B| = 0 / |B| = 0\")\n",
    "print(\"  → BSS_ρ = |A \\\\ B| / |B| = |A| / |B| ≈ 1\")\n",
    "print(\"\\nDemonstration:\")\n",
    "\n",
    "for (s_label, s_basic), (l_label, l_basic) in zip(sensory_basics[:2], language_basics[:2]):\n",
    "    bss_tau = s_basic.bss_tau(l_basic)\n",
    "    bss_rho = s_basic.bss_rho(l_basic)\n",
    "    print(f\"  {s_label}: BSS_τ = {bss_tau:.3f}, BSS_ρ = {bss_rho:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRECT APPROACH: Compare by STRUCTURE, not content\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nWe need to compare graph topology (node degrees, morphisms)\")\n",
    "print(\"not node content (HLLSet intersection).\")\n",
    "print(\"\\nSee full lattice comparison below for structural matching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98150aac",
   "metadata": {},
   "source": [
    "## Example 2: Abstract Concepts\n",
    "\n",
    "**Concept: \"Justice\"**\n",
    "\n",
    "- **Sensory representation**: Limited or indirect (scales, courtroom, etc.)\n",
    "- **Language representation**: Rich semantic network\n",
    "\n",
    "We expect **lower ε-isomorphism** (weak grounding) for abstract concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb77696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract Concepts:\n",
      "\n",
      "JUSTICE:\n",
      "  Sensory: 4 features\n",
      "  Language: 10 features\n",
      "\n",
      "FREEDOM:\n",
      "  Sensory: 4 features\n",
      "  Language: 9 features\n",
      "\n",
      "INFINITY:\n",
      "  Sensory: 4 features\n",
      "  Language: 9 features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Abstract concepts with limited sensory grounding\n",
    "abstract_concepts = {\n",
    "    'justice': {\n",
    "        'sensory': ['scales_image', 'courtroom_visual', 'gavel_sound', 'formal_setting'],\n",
    "        'language': ['fairness', 'equality', 'law', 'rights', 'moral', 'equity', \n",
    "                     'impartial', 'judgment', 'legal_system', 'ethics']\n",
    "    },\n",
    "    'freedom': {\n",
    "        'sensory': ['open_space', 'bird_flying', 'no_barriers', 'movement'],\n",
    "        'language': ['liberty', 'autonomy', 'independence', 'choice', 'rights',\n",
    "                     'democracy', 'unconstrained', 'self_determination', 'political']\n",
    "    },\n",
    "    'infinity': {\n",
    "        'sensory': ['endless_horizon', 'night_sky', 'vast_ocean', 'repeating_pattern'],\n",
    "        'language': ['unbounded', 'limitless', 'eternal', 'mathematical', 'endless',\n",
    "                     'perpetual', 'infinite', 'without_end', 'continuous']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Abstract Concepts:\\n\")\n",
    "for concept, channels in abstract_concepts.items():\n",
    "    print(f\"{concept.upper()}:\")\n",
    "    print(f\"  Sensory: {len(channels['sensory'])} features\")\n",
    "    print(f\"  Language: {len(channels['language'])} features\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50066652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 abstract concept pairs\n",
      "\n",
      "Note: Cross-modal BSS comparison is meaningless (disjoint token spaces)\n",
      "We'll use structural lattice comparison instead.\n"
     ]
    }
   ],
   "source": [
    "# Create BasicHLLSets for abstract concepts\n",
    "abstract_sensory = []\n",
    "abstract_language = []\n",
    "\n",
    "for idx, (concept, channels) in enumerate(abstract_concepts.items()):\n",
    "    # Sensory\n",
    "    s_hllset = kernel.absorb(channels['sensory'])\n",
    "    s_basic = BasicHLLSet(index=idx, is_row=True, hllset=s_hllset, config=config)\n",
    "    abstract_sensory.append((concept, s_basic))\n",
    "    \n",
    "    # Language\n",
    "    l_hllset = kernel.absorb(channels['language'])\n",
    "    l_basic = BasicHLLSet(index=idx, is_row=True, hllset=l_hllset, config=config)\n",
    "    abstract_language.append((concept, l_basic))\n",
    "\n",
    "print(f\"Created {len(abstract_sensory)} abstract concept pairs\")\n",
    "print(\"\\nNote: Cross-modal BSS comparison is meaningless (disjoint token spaces)\")\n",
    "print(\"We'll use structural lattice comparison instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2966659",
   "metadata": {},
   "source": [
    "## Full Lattice Comparison: Structural Matching\n",
    "\n",
    "**Key Insight**: We compare lattices by STRUCTURE (graph topology), not by node content.\n",
    "\n",
    "Algorithm:\n",
    "1. Compute node degrees (morphism counts) in each lattice\n",
    "2. Match nodes by degree similarity  \n",
    "3. Measure structural alignment via degree correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760863fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building complete lattices...\n",
      "  Sensory tokens: 16\n",
      "  Language tokens: 27\n",
      "  Small lattice dimension: 130\n"
     ]
    }
   ],
   "source": [
    "# Create full lattices with 4 concepts each\n",
    "# Simplify by creating small lattices\n",
    "\n",
    "# Combine grounded and abstract for sensory lattice\n",
    "all_sensory_tokens = (\n",
    "    sensory_features['red'] + sensory_features['round'] + \n",
    "    abstract_concepts['justice']['sensory'] + abstract_concepts['freedom']['sensory']\n",
    ")\n",
    "\n",
    "# Combine for language lattice\n",
    "all_language_tokens = (\n",
    "    language_features['red'] + language_features['round'] +\n",
    "    abstract_concepts['justice']['language'] + abstract_concepts['freedom']['language']\n",
    ")\n",
    "\n",
    "print(f\"Building complete lattices...\")\n",
    "print(f\"  Sensory tokens: {len(all_sensory_tokens)}\")\n",
    "print(f\"  Language tokens: {len(all_language_tokens)}\")\n",
    "\n",
    "# Create small config for demonstration\n",
    "small_config = HRTConfig(\n",
    "    p_bits=4,  # Smaller dimension\n",
    "    h_bits=8,\n",
    "    tau=0.6,\n",
    "    rho=0.3,\n",
    "    epsilon=0.15\n",
    ")\n",
    "\n",
    "print(f\"  Small lattice dimension: {small_config.dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a7520d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Lattices populated\n"
     ]
    }
   ],
   "source": [
    "# Create lattices\n",
    "lattice_sensory = HLLSetLattice.empty(small_config)\n",
    "lattice_language = HLLSetLattice.empty(small_config)\n",
    "\n",
    "# Populate a few row basics with actual data\n",
    "for i in range(min(4, small_config.dimension)):\n",
    "    # Sensory\n",
    "    if i < len(sensory_features):\n",
    "        label = list(sensory_features.keys())[i]\n",
    "        tokens = sensory_features[label]\n",
    "        hllset_s = kernel.absorb(tokens)\n",
    "        lattice_sensory = lattice_sensory.with_row_basic(i, hllset_s)\n",
    "    \n",
    "    # Language\n",
    "    if i < len(language_features):\n",
    "        label = list(language_features.keys())[i]\n",
    "        tokens = language_features[label]\n",
    "        hllset_l = kernel.absorb(tokens)\n",
    "        lattice_language = lattice_language.with_row_basic(i, hllset_l)\n",
    "\n",
    "print(\"✓ Lattices populated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da7c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STANDARDIZED LATTICE COMPARISON (Structural)\n",
      "======================================================================\n",
      "\n",
      "Structural Metrics:\n",
      "  Row degree correlation:     0.000\n",
      "  Col degree correlation:     0.000\n",
      "  Row degree distance:        0.000\n",
      "  Col degree distance:        0.000\n",
      "\n",
      "  Overall structure match:    0.000\n",
      "  ε-isomorphism probability:  0.000\n",
      "\n",
      "Semantic Grounding Level: Disconnected (no grounding)\n",
      "\n",
      "Interpretation:\n",
      "  • High correlation → Similar graph topology\n",
      "  • Low distance → Similar degree distributions\n",
      "  • High ε-iso prob → Strong structural alignment (meaning!)\n"
     ]
    }
   ],
   "source": [
    "# Use standardized lattice comparison (structural)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STANDARDIZED LATTICE COMPARISON (Structural)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics = lattice_sensory.compare_lattices(lattice_language)\n",
    "\n",
    "print(\"\\nStructural Metrics:\")\n",
    "print(f\"  Row degree correlation:     {metrics['row_degree_correlation']:.3f}\")\n",
    "print(f\"  Col degree correlation:     {metrics['col_degree_correlation']:.3f}\")\n",
    "print(f\"  Row degree distance:        {metrics['row_degree_distance']:.3f}\")\n",
    "print(f\"  Col degree distance:        {metrics['col_degree_distance']:.3f}\")\n",
    "print(f\"\\n  Overall structure match:    {metrics['overall_structure_match']:.3f}\")\n",
    "print(f\"  ε-isomorphism probability:  {metrics['epsilon_isomorphic_prob']:.3f}\")\n",
    "\n",
    "# Get grounding level classification\n",
    "grounding_level = lattice_sensory.semantic_grounding_level(lattice_language)\n",
    "print(f\"\\nSemantic Grounding Level: {grounding_level}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  • High correlation → Similar graph topology\")\n",
    "print(\"  • Low distance → Similar degree distributions\")\n",
    "print(\"  • High ε-iso prob → Strong structural alignment (meaning!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f210a",
   "metadata": {},
   "source": [
    "## Interpretation: ε-Isomorphism as Meaning\n",
    "\n",
    "**ε-Isomorphism Probability** (based on structural similarity) measures semantic grounding:\n",
    "\n",
    "- **P ≥ 0.7**: Strong grounding (similar graph structure)\n",
    "  - Example: Sensory and language lattices with similar connectivity patterns\n",
    "  - Language well-aligned with sensory experience structurally\n",
    "\n",
    "- **0.5 ≤ P < 0.7**: Moderate grounding (partial structural similarity)\n",
    "  - Example: Some shared patterns, but divergent topology\n",
    "  - Partial sensory anchors, extended abstractly\n",
    "\n",
    "- **0.3 ≤ P < 0.5**: Weak grounding (different structures)\n",
    "  - Example: Abstract concepts with sparse sensory connections\n",
    "  - Linguistic structure rich, sensory structure sparse\n",
    "\n",
    "- **P < 0.3**: Disconnected (no structural correspondence)\n",
    "  - Example: Completely different graph topologies\n",
    "  - No structural grounding\n",
    "\n",
    "**Key Insight**: Meaning arises from **structural correspondence** (graph isomorphism), NOT from node content overlap (which is zero for cross-modal lattices!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbc7fd",
   "metadata": {},
   "source": [
    "## Metaphorical Extension\n",
    "\n",
    "Abstract concepts often built through **morphisms** from grounded concepts.\n",
    "\n",
    "**Example: \"Time flows\"**\n",
    "- Temporal structure ← Spatial/fluid structure\n",
    "- W_time inherits structure from W_space via morphism\n",
    "- Metaphor = morphism chain in lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97720927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaphorical Mapping: Space → Time\n",
      "==================================================\n",
      "\n",
      "Spatial tokens: ['move', 'forward', 'back', 'through', 'flow', 'pass', 'ahead']\n",
      "Temporal tokens: ['future', 'past', 'before', 'after', 'progress', 'pass', 'ahead']\n",
      "Shared tokens: {'ahead', 'pass'}\n",
      "\n",
      "BSS_τ (Space → Time): 0.429\n",
      "BSS_ρ (Space → Time): 0.714\n",
      "Morphism exists: ✗\n",
      "\n",
      "Interpretation:\n",
      "  → Metaphor is WEAK (no strong morphism)\n",
      "  → Limited structural transfer\n",
      "\n",
      "Note: This example has shared tokens ('pass', 'ahead'), so BSS is meaningful.\n",
      "For truly disjoint cross-modal lattices, use structural comparison instead.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate metaphorical extension\n",
    "spatial_tokens = ['move', 'forward', 'back', 'through', 'flow', 'pass', 'ahead']\n",
    "temporal_tokens = ['future', 'past', 'before', 'after', 'progress', 'pass', 'ahead']\n",
    "\n",
    "spatial_hllset = kernel.absorb(spatial_tokens)\n",
    "temporal_hllset = kernel.absorb(temporal_tokens)\n",
    "\n",
    "spatial_basic = BasicHLLSet(index=0, is_row=True, hllset=spatial_hllset, config=config)\n",
    "temporal_basic = BasicHLLSet(index=1, is_row=True, hllset=temporal_hllset, config=config)\n",
    "\n",
    "print(\"Metaphorical Mapping: Space → Time\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use regular bss_tau/bss_rho (these share some tokens, so BSS is meaningful)\n",
    "bss_tau = spatial_basic.bss_tau(temporal_basic)\n",
    "bss_rho = spatial_basic.bss_rho(temporal_basic)\n",
    "has_morphism = spatial_basic.has_morphism_to(temporal_basic)\n",
    "\n",
    "print(f\"\\nSpatial tokens: {spatial_tokens}\")\n",
    "print(f\"Temporal tokens: {temporal_tokens}\")\n",
    "print(f\"Shared tokens: {set(spatial_tokens) & set(temporal_tokens)}\")\n",
    "print(f\"\\nBSS_τ (Space → Time): {bss_tau:.3f}\")\n",
    "print(f\"BSS_ρ (Space → Time): {bss_rho:.3f}\")\n",
    "print(f\"Morphism exists: {'✓' if has_morphism else '✗'}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if has_morphism:\n",
    "    print(\"  → Metaphor is GROUNDED via morphism\")\n",
    "    print(\"  → Temporal concepts inherit spatial structure\")\n",
    "    print(\"  → 'Time flows' makes sense because flow(space) → progress(time)\")\n",
    "else:\n",
    "    print(\"  → Metaphor is WEAK (no strong morphism)\")\n",
    "    print(\"  → Limited structural transfer\")\n",
    "\n",
    "print(\"\\nNote: This example has shared tokens ('pass', 'ahead'), so BSS is meaningful.\")\n",
    "print(\"For truly disjoint cross-modal lattices, use structural comparison instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35eae6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Senses and Signs in HRT:**\n",
    "\n",
    "1. **Dual-Channel Perception**\n",
    "   - W_sensory: Perceptual lattice (grounded in reality)\n",
    "   - W_language: Linguistic lattice (symbolic representation)\n",
    "   - **Key**: Token spaces are DISJOINT (no intersection)\n",
    "\n",
    "2. **Entanglement as Meaning**\n",
    "   - Meaning = **structural correspondence** between lattices (graph topology)\n",
    "   - NOT node content overlap (impossible with disjoint token spaces)\n",
    "   - Measured by ε-isomorphism probability via degree correlation\n",
    "\n",
    "3. **Structural Comparison**\n",
    "   - Compute node degrees (morphism counts) in each lattice\n",
    "   - Match nodes by degree similarity\n",
    "   - Measure correlation and distance of degree sequences\n",
    "   - Standardized API: `compare_lattices()` → structural metrics\n",
    "\n",
    "4. **Grounding Levels** (via structural similarity)\n",
    "   - Strong (P ≥ 0.7): Similar graph structures\n",
    "   - Moderate (0.5 ≤ P < 0.7): Partial structural similarity\n",
    "   - Weak (0.3 ≤ P < 0.5): Different structures\n",
    "   - Disconnected (P < 0.3): No structural correspondence\n",
    "\n",
    "5. **Metaphorical Extension**\n",
    "   - Abstract concepts built via morphisms from grounded concepts\n",
    "   - Example: Time inherits structure from Space\n",
    "   - Metaphor = morphism chain preserving structure\n",
    "\n",
    "**Critical Insight**: \n",
    "- BSS (intersection-based) only works WITHIN a lattice\n",
    "- Cross-modal comparison requires STRUCTURAL matching (degree-based)\n",
    "- Meaning emerges from graph isomorphism, NOT token overlap\n",
    "\n",
    "**References:**\n",
    "- **DOCS/SENSES_SIGNS_SAUSSURE.md**: Complete theoretical framework\n",
    "- **DOCS/EPSILON_ISOMORPHISM.md**: ε-isomorphism definition\n",
    "- **DOCS/HRT_LATTICE_THEORY.md**: W lattice structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc587484",
   "metadata": {},
   "source": [
    "## Application: Hallucination Detection in Generated Text\n",
    "\n",
    "**Saussure Principle Applied to AI Systems:**\n",
    "\n",
    "- **W_reality (Sensory Lattice)**: Knowledge base / ground truth of the AI system\n",
    "- **W_generated (Language Lattice)**: Generated text output\n",
    "- **Structural Match**: Generated text should match the topological structure of reality\n",
    "- **Hallucination**: Generated text with structure disconnected from reality\n",
    "\n",
    "**Detection Algorithm:**\n",
    "1. Build W_reality from system's knowledge base\n",
    "2. Build W_generated from output text\n",
    "3. Compare structural similarity\n",
    "4. High ε-isomorphism → Grounded (factual)\n",
    "5. Low ε-isomorphism → Hallucination (creative/false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc98868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Diagnosis System\n",
      "============================================================\n",
      "\n",
      "Knowledge Base: 18 facts\n",
      "Grounded Generation: 14 statements\n",
      "Hallucinated Generation: 11 statements\n"
     ]
    }
   ],
   "source": [
    "# Example: Medical diagnosis system\n",
    "# W_reality = Knowledge base of actual medical facts\n",
    "# W_generated = AI's diagnostic explanation\n",
    "\n",
    "# Knowledge base (ground truth about a condition)\n",
    "medical_facts = {\n",
    "    'symptoms': ['fever', 'cough', 'fatigue', 'shortness_breath', 'body_aches'],\n",
    "    'causes': ['viral_infection', 'respiratory_virus', 'contagious', 'airborne'],\n",
    "    'treatment': ['rest', 'fluids', 'symptom_relief', 'isolation', 'monitor'],\n",
    "    'duration': ['acute', 'seven_days', 'temporary', 'recovery_period']\n",
    "}\n",
    "\n",
    "# Grounded generation (matches reality structure)\n",
    "grounded_text = {\n",
    "    'symptoms': ['patient_fever', 'persistent_cough', 'tired', 'breathing_difficulty'],\n",
    "    'causes': ['viral_pathogen', 'respiratory_infection', 'transmitted_contact'],\n",
    "    'treatment': ['bed_rest', 'hydration', 'pain_relief', 'quarantine'],\n",
    "    'duration': ['short_term', 'one_week', 'self_limiting']\n",
    "}\n",
    "\n",
    "# Hallucinated generation (disconnected from reality)\n",
    "hallucinated_text = {\n",
    "    'quantum_effects': ['energy_healing', 'chakra_alignment', 'crystal_therapy'],\n",
    "    'alien_cause': ['extraterrestrial', 'mind_control', 'conspiracy'],\n",
    "    'magic_cure': ['essential_oils', 'homeopathy', 'prayer_only'],\n",
    "    'instant': ['immediate_cure', 'no_recovery_time']\n",
    "}\n",
    "\n",
    "print(\"Medical Diagnosis System\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nKnowledge Base: {sum(len(v) for v in medical_facts.values())} facts\")\n",
    "print(f\"Grounded Generation: {sum(len(v) for v in grounded_text.values())} statements\")\n",
    "print(f\"Hallucinated Generation: {sum(len(v) for v in hallucinated_text.values())} statements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3cf3ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building lattices...\n",
      "✓ Reality lattice built\n",
      "✓ Grounded generation lattice built\n",
      "✓ Hallucinated generation lattice built\n"
     ]
    }
   ],
   "source": [
    "# Build lattices\n",
    "print(\"\\nBuilding lattices...\")\n",
    "\n",
    "# W_reality: Knowledge base lattice\n",
    "reality_lattice = HLLSetLattice.empty(small_config)\n",
    "for i, (category, facts) in enumerate(medical_facts.items()):\n",
    "    if i < small_config.dimension:\n",
    "        hllset = kernel.absorb(facts)\n",
    "        reality_lattice = reality_lattice.with_row_basic(i, hllset)\n",
    "\n",
    "# W_grounded: Grounded generation lattice\n",
    "grounded_lattice = HLLSetLattice.empty(small_config)\n",
    "for i, (category, statements) in enumerate(grounded_text.items()):\n",
    "    if i < small_config.dimension:\n",
    "        hllset = kernel.absorb(statements)\n",
    "        grounded_lattice = grounded_lattice.with_row_basic(i, hllset)\n",
    "\n",
    "# W_hallucinated: Hallucinated generation lattice\n",
    "hallucinated_lattice = HLLSetLattice.empty(small_config)\n",
    "for i, (category, statements) in enumerate(hallucinated_text.items()):\n",
    "    if i < small_config.dimension:\n",
    "        hllset = kernel.absorb(statements)\n",
    "        hallucinated_lattice = hallucinated_lattice.with_row_basic(i, hllset)\n",
    "\n",
    "print(\"✓ Reality lattice built\")\n",
    "print(\"✓ Grounded generation lattice built\")\n",
    "print(\"✓ Hallucinated generation lattice built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a28ba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HALLUCINATION DETECTION: Reality vs Grounded Generation\n",
      "======================================================================\n",
      "\n",
      "Structural Metrics:\n",
      "  Degree correlation:      0.000\n",
      "  Degree distance:         0.000\n",
      "  ε-isomorphism prob:      0.000\n",
      "\n",
      "Grounding Level: Disconnected (no grounding)\n",
      "\n",
      "✗ HALLUCINATION: Generated text structure diverges from reality\n",
      "  Text may contain false or inconsistent information\n"
     ]
    }
   ],
   "source": [
    "# Compare structural similarity: Reality vs Grounded\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HALLUCINATION DETECTION: Reality vs Grounded Generation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_grounded = reality_lattice.compare_lattices(grounded_lattice)\n",
    "\n",
    "print(\"\\nStructural Metrics:\")\n",
    "print(f\"  Degree correlation:      {metrics_grounded['overall_structure_match']:.3f}\")\n",
    "print(f\"  Degree distance:         {(metrics_grounded['row_degree_distance'] + metrics_grounded['col_degree_distance'])/2:.3f}\")\n",
    "print(f\"  ε-isomorphism prob:      {metrics_grounded['epsilon_isomorphic_prob']:.3f}\")\n",
    "\n",
    "grounding_grounded = reality_lattice.semantic_grounding_level(grounded_lattice)\n",
    "print(f\"\\nGrounding Level: {grounding_grounded}\")\n",
    "\n",
    "if metrics_grounded['epsilon_isomorphic_prob'] >= 0.5:\n",
    "    print(\"\\n✓ GROUNDED: Generated text structure matches reality\")\n",
    "    print(\"  Text is likely factual and consistent with knowledge base\")\n",
    "else:\n",
    "    print(\"\\n✗ HALLUCINATION: Generated text structure diverges from reality\")\n",
    "    print(\"  Text may contain false or inconsistent information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "285b761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HALLUCINATION DETECTION: Reality vs Hallucinated Generation\n",
      "======================================================================\n",
      "\n",
      "Structural Metrics:\n",
      "  Degree correlation:      0.000\n",
      "  Degree distance:         0.000\n",
      "  ε-isomorphism prob:      0.000\n",
      "\n",
      "Grounding Level: Disconnected (no grounding)\n",
      "\n",
      "✗ HALLUCINATION: Generated text structure diverges from reality\n",
      "  Text may contain false or inconsistent information\n"
     ]
    }
   ],
   "source": [
    "# Compare structural similarity: Reality vs Hallucinated\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HALLUCINATION DETECTION: Reality vs Hallucinated Generation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_hallucinated = reality_lattice.compare_lattices(hallucinated_lattice)\n",
    "\n",
    "print(\"\\nStructural Metrics:\")\n",
    "print(f\"  Degree correlation:      {metrics_hallucinated['overall_structure_match']:.3f}\")\n",
    "print(f\"  Degree distance:         {(metrics_hallucinated['row_degree_distance'] + metrics_hallucinated['col_degree_distance'])/2:.3f}\")\n",
    "print(f\"  ε-isomorphism prob:      {metrics_hallucinated['epsilon_isomorphic_prob']:.3f}\")\n",
    "\n",
    "grounding_hallucinated = reality_lattice.semantic_grounding_level(hallucinated_lattice)\n",
    "print(f\"\\nGrounding Level: {grounding_hallucinated}\")\n",
    "\n",
    "if metrics_hallucinated['epsilon_isomorphic_prob'] >= 0.5:\n",
    "    print(\"\\n✓ GROUNDED: Generated text structure matches reality\")\n",
    "    print(\"  Text is likely factual and consistent with knowledge base\")\n",
    "else:\n",
    "    print(\"\\n✗ HALLUCINATION: Generated text structure diverges from reality\")\n",
    "    print(\"  Text may contain false or inconsistent information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e495a27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARISON SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Type                 ε-iso Prob      Status               Assessment\n",
      "----------------------------------------------------------------------\n",
      "Grounded Text        0.000           ✗ Hallucination      Factual\n",
      "Hallucinated Text    0.000           ✗ Hallucination      False/Creative\n",
      "\n",
      "======================================================================\n",
      "Key Insight:\n",
      "======================================================================\n",
      "Generated text with HIGH structural similarity to reality → GROUNDED\n",
      "Generated text with LOW structural similarity to reality → HALLUCINATION\n",
      "\n",
      "Saussure Principle: Meaning = Structural Correspondence\n",
      "Applied to AI: Factual = Topological Match with Knowledge Base\n"
     ]
    }
   ],
   "source": [
    "# Comparison Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Type':<20} {'ε-iso Prob':<15} {'Status':<20} {'Assessment'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "grounded_prob = metrics_grounded['epsilon_isomorphic_prob']\n",
    "halluc_prob = metrics_hallucinated['epsilon_isomorphic_prob']\n",
    "\n",
    "grounded_status = \"✓ Grounded\" if grounded_prob >= 0.5 else \"✗ Hallucination\"\n",
    "halluc_status = \"✓ Grounded\" if halluc_prob >= 0.5 else \"✗ Hallucination\"\n",
    "\n",
    "print(f\"{'Grounded Text':<20} {grounded_prob:<15.3f} {grounded_status:<20} Factual\")\n",
    "print(f\"{'Hallucinated Text':<20} {halluc_prob:<15.3f} {halluc_status:<20} False/Creative\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Key Insight:\")\n",
    "print(\"=\"*70)\n",
    "print(\"Generated text with HIGH structural similarity to reality → GROUNDED\")\n",
    "print(\"Generated text with LOW structural similarity to reality → HALLUCINATION\")\n",
    "print(\"\\nSaussure Principle: Meaning = Structural Correspondence\")\n",
    "print(\"Applied to AI: Factual = Topological Match with Knowledge Base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f903df6",
   "metadata": {},
   "source": [
    "## Use Cases for Hallucination Detection\n",
    "\n",
    "### 1. Factual QA Systems\n",
    "- Build W_reality from knowledge base\n",
    "- Compare each answer's W_generated to W_reality\n",
    "- Flag low ε-isomorphism as potential hallucination\n",
    "\n",
    "### 2. Medical AI\n",
    "- W_reality = Medical literature + validated protocols\n",
    "- W_generated = AI's diagnostic recommendations\n",
    "- Structural mismatch → Dangerous hallucination (reject)\n",
    "\n",
    "### 3. Creative Writing (Intentional Hallucination)\n",
    "- W_reality = Real-world constraints\n",
    "- W_generated = Fantasy narrative\n",
    "- **Target LOW ε-isomorphism** for creative freedom\n",
    "- Still check internal consistency (W_generated self-coherence)\n",
    "\n",
    "### 4. Code Generation\n",
    "- W_reality = API documentation + valid syntax\n",
    "- W_generated = Generated code\n",
    "- Structural match → Likely correct\n",
    "- Structural mismatch → Syntax errors or invalid API calls\n",
    "\n",
    "### 5. Real-time Monitoring\n",
    "- Continuously compare generated output to knowledge base structure\n",
    "- Set thresholds: P < 0.3 → High-confidence hallucination (reject/flag)\n",
    "- P ∈ [0.3, 0.5] → Uncertain (request verification)\n",
    "- P ≥ 0.5 → Likely grounded (accept)\n",
    "\n",
    "**Key Advantage**: Structural comparison detects hallucinations **without** needing to verify every fact individually. Graph topology reveals systematic divergence from reality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638b232",
   "metadata": {},
   "source": [
    "## Application: Language Translation via Sensory Grounding\n",
    "\n",
    "**Translation Model**: W(L1) → W(Sensory) → W(L2) ⟹ L1 → L2\n",
    "\n",
    "Languages differ in vocabulary but represent the **same reality**. Translation works through shared sensory grounding:\n",
    "\n",
    "- **W(English)**: English language lattice\n",
    "- **W(Sensory)**: Shared conceptual/sensory reality\n",
    "- **W(French)**: French language lattice\n",
    "\n",
    "**Translation Quality**:\n",
    "- Both languages well-grounded → High-quality translation\n",
    "- One language abstract → Translation loss\n",
    "- Structural correspondence through shared reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd7a9d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Translation via Sensory Grounding\n",
      "======================================================================\n",
      "\n",
      "Shared Reality: 16 sensory features\n",
      "English: 20 linguistic features\n",
      "French: 20 linguistic features\n"
     ]
    }
   ],
   "source": [
    "# Example: Color concepts across languages\n",
    "# Shared sensory reality: Physical color spectrum\n",
    "\n",
    "# Sensory reality (wavelengths and perceptual features)\n",
    "sensory_color_reality = {\n",
    "    'red_region': ['wavelength_650nm', 'long_wave', 'warm_sensation', 'arousing'],\n",
    "    'blue_region': ['wavelength_470nm', 'short_wave', 'cool_sensation', 'calming'],\n",
    "    'green_region': ['wavelength_520nm', 'mid_wave', 'neutral_temp', 'balanced'],\n",
    "    'yellow_region': ['wavelength_580nm', 'mid_long_wave', 'bright', 'cheerful']\n",
    "}\n",
    "\n",
    "# English color vocabulary\n",
    "english_colors = {\n",
    "    'red': ['primary_color', 'stop_signal', 'danger', 'passion', 'fire'],\n",
    "    'blue': ['primary_color', 'sky', 'ocean', 'calm', 'trust'],\n",
    "    'green': ['secondary_color', 'nature', 'growth', 'grass', 'go_signal'],\n",
    "    'yellow': ['primary_color', 'sun', 'caution', 'brightness', 'warning']\n",
    "}\n",
    "\n",
    "# French color vocabulary\n",
    "french_colors = {\n",
    "    'rouge': ['couleur_primaire', 'arrêt', 'danger', 'amour', 'feu'],\n",
    "    'bleu': ['couleur_primaire', 'ciel', 'mer', 'tranquillité', 'confiance'],\n",
    "    'vert': ['couleur_secondaire', 'nature', 'croissance', 'herbe', 'passage'],\n",
    "    'jaune': ['couleur_primaire', 'soleil', 'attention', 'luminosité', 'prudence']\n",
    "}\n",
    "\n",
    "print(\"Language Translation via Sensory Grounding\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nShared Reality: {sum(len(v) for v in sensory_color_reality.values())} sensory features\")\n",
    "print(f\"English: {sum(len(v) for v in english_colors.values())} linguistic features\")\n",
    "print(f\"French: {sum(len(v) for v in french_colors.values())} linguistic features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb014115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building lattices...\n",
      "✓ W_Sensory (shared reality)\n",
      "✓ W_English\n",
      "✓ W_French\n"
     ]
    }
   ],
   "source": [
    "# Build three lattices\n",
    "print(\"\\nBuilding lattices...\")\n",
    "\n",
    "# W_Sensory: Shared reality\n",
    "sensory_lattice_trans = HLLSetLattice.empty(small_config)\n",
    "for i, (region, features) in enumerate(sensory_color_reality.items()):\n",
    "    if i < small_config.dimension:\n",
    "        hllset = kernel.absorb(features)\n",
    "        sensory_lattice_trans = sensory_lattice_trans.with_row_basic(i, hllset)\n",
    "\n",
    "# W_English: English language\n",
    "english_lattice = HLLSetLattice.empty(small_config)\n",
    "for i, (color, features) in enumerate(english_colors.items()):\n",
    "    if i < small_config.dimension:\n",
    "        hllset = kernel.absorb(features)\n",
    "        english_lattice = english_lattice.with_row_basic(i, hllset)\n",
    "\n",
    "# W_French: French language\n",
    "french_lattice = HLLSetLattice.empty(small_config)\n",
    "for i, (color, features) in enumerate(french_colors.items()):\n",
    "    if i < small_config.dimension:\n",
    "        hllset = kernel.absorb(features)\n",
    "        french_lattice = french_lattice.with_row_basic(i, hllset)\n",
    "\n",
    "print(\"✓ W_Sensory (shared reality)\")\n",
    "print(\"✓ W_English\")\n",
    "print(\"✓ W_French\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "095dd638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: English → Sensory Grounding\n",
      "======================================================================\n",
      "\n",
      "Structural Similarity:\n",
      "  Degree correlation:    0.000\n",
      "  ε-isomorphism prob:    0.000\n",
      "\n",
      "English Grounding: Disconnected (no grounding)\n",
      "  → English color vocabulary is poorly grounded in sensory reality\n"
     ]
    }
   ],
   "source": [
    "# Step 1: English → Sensory grounding\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: English → Sensory Grounding\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_en_to_sensory = english_lattice.compare_lattices(sensory_lattice_trans)\n",
    "\n",
    "print(f\"\\nStructural Similarity:\")\n",
    "print(f\"  Degree correlation:    {metrics_en_to_sensory['overall_structure_match']:.3f}\")\n",
    "print(f\"  ε-isomorphism prob:    {metrics_en_to_sensory['epsilon_isomorphic_prob']:.3f}\")\n",
    "\n",
    "grounding_en = english_lattice.semantic_grounding_level(sensory_lattice_trans)\n",
    "print(f\"\\nEnglish Grounding: {grounding_en}\")\n",
    "print(f\"  → English color vocabulary is {'well-' if metrics_en_to_sensory['epsilon_isomorphic_prob'] >= 0.5 else 'poorly '}grounded in sensory reality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c86c950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: French → Sensory Grounding\n",
      "======================================================================\n",
      "\n",
      "Structural Similarity:\n",
      "  Degree correlation:    0.000\n",
      "  ε-isomorphism prob:    0.000\n",
      "\n",
      "French Grounding: Disconnected (no grounding)\n",
      "  → French color vocabulary is poorly grounded in sensory reality\n"
     ]
    }
   ],
   "source": [
    "# Step 2: French → Sensory grounding\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: French → Sensory Grounding\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_fr_to_sensory = french_lattice.compare_lattices(sensory_lattice_trans)\n",
    "\n",
    "print(f\"\\nStructural Similarity:\")\n",
    "print(f\"  Degree correlation:    {metrics_fr_to_sensory['overall_structure_match']:.3f}\")\n",
    "print(f\"  ε-isomorphism prob:    {metrics_fr_to_sensory['epsilon_isomorphic_prob']:.3f}\")\n",
    "\n",
    "grounding_fr = french_lattice.semantic_grounding_level(sensory_lattice_trans)\n",
    "print(f\"\\nFrench Grounding: {grounding_fr}\")\n",
    "print(f\"  → French color vocabulary is {'well-' if metrics_fr_to_sensory['epsilon_isomorphic_prob'] >= 0.5 else 'poorly '}grounded in sensory reality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49953d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: Translation Quality (English → French)\n",
      "======================================================================\n",
      "\n",
      "Direct Structural Similarity (En → Fr):\n",
      "  Degree correlation:    0.000\n",
      "  ε-isomorphism prob:    0.000\n",
      "\n",
      "Translation Quality via Shared Grounding:\n",
      "  English grounding:     0.000\n",
      "  French grounding:      0.000\n",
      "  Translation quality:   0.000\n",
      "  Formula: min(P(En≈S), P(Fr≈S))\n",
      "\n",
      "======================================================================\n",
      "Interpretation:\n",
      "======================================================================\n",
      "✗ TRANSLATION LOSS\n",
      "  At least one language poorly grounded in sensory reality\n",
      "  Meaning may be lost or distorted in translation\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Translation Quality (English → French)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Translation Quality (English → French)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Direct comparison (without sensory grounding)\n",
    "metrics_en_to_fr = english_lattice.compare_lattices(french_lattice)\n",
    "\n",
    "print(f\"\\nDirect Structural Similarity (En → Fr):\")\n",
    "print(f\"  Degree correlation:    {metrics_en_to_fr['overall_structure_match']:.3f}\")\n",
    "print(f\"  ε-isomorphism prob:    {metrics_en_to_fr['epsilon_isomorphic_prob']:.3f}\")\n",
    "\n",
    "# Translation quality via sensory grounding\n",
    "en_grounding = metrics_en_to_sensory['epsilon_isomorphic_prob']\n",
    "fr_grounding = metrics_fr_to_sensory['epsilon_isomorphic_prob']\n",
    "translation_quality = min(en_grounding, fr_grounding)\n",
    "\n",
    "print(f\"\\nTranslation Quality via Shared Grounding:\")\n",
    "print(f\"  English grounding:     {en_grounding:.3f}\")\n",
    "print(f\"  French grounding:      {fr_grounding:.3f}\")\n",
    "print(f\"  Translation quality:   {translation_quality:.3f}\")\n",
    "print(f\"  Formula: min(P(En≈S), P(Fr≈S))\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Interpretation:\")\n",
    "print(\"=\"*70)\n",
    "if translation_quality >= 0.5:\n",
    "    print(\"✓ HIGH-QUALITY TRANSLATION\")\n",
    "    print(\"  Both languages well-grounded in shared sensory reality\")\n",
    "    print(\"  Translation preserves meaning through structural correspondence\")\n",
    "else:\n",
    "    print(\"✗ TRANSLATION LOSS\")\n",
    "    print(\"  At least one language poorly grounded in sensory reality\")\n",
    "    print(\"  Meaning may be lost or distorted in translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada98c68",
   "metadata": {},
   "source": [
    "## Translation Principle\n",
    "\n",
    "**Key Insight**: Translation works through **shared structural grounding**, not direct word mapping.\n",
    "\n",
    "### Translation Path\n",
    "```\n",
    "W(English) → W(Sensory) → W(French)\n",
    "```\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "1. **Shared Reality**: Both languages describe the same physical/conceptual reality\n",
    "2. **Structural Correspondence**: If both have similar graph topology relative to reality\n",
    "3. **Transitivity**: Meaning preserved through structural alignment\n",
    "\n",
    "### Translation Quality Factors\n",
    "\n",
    "- **High quality**: Both languages well-grounded (concrete concepts like colors, objects)\n",
    "- **Medium quality**: One language more grounded (technical terms, cultural concepts)\n",
    "- **Low quality**: Both languages abstract (philosophical concepts, poetry)\n",
    "\n",
    "### Untranslatable Concepts\n",
    "\n",
    "When W(L1) structure differs from W(L2) structure relative to same reality:\n",
    "- Example: German \"Schadenfreude\" (taking pleasure in others' misfortune)\n",
    "- English lacks equivalent single-word structure\n",
    "- Requires multi-word description, losing structural elegance\n",
    "\n",
    "### Multi-Lingual Systems\n",
    "\n",
    "For N languages:\n",
    "```\n",
    "W(L1) ⟷ W(Sensory) ⟷ W(L2) ⟷ ... ⟷ W(LN)\n",
    "```\n",
    "\n",
    "All connected through shared reality. Translation quality depends on shortest structural path through sensory grounding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hllset-manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
