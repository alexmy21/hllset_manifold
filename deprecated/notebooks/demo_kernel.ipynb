{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLLSet Kernel Demo\n",
    "\n",
    "Interactive exploration of the Content-Addressed Immutable HLLSet Framework.\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "1. **Content-Addressed**: HLLSet name = SHA1(register contents)\n",
    "2. **Immutable**: Operations return NEW HLLSets, never modify\n",
    "3. **No Semantic Names**: Only external reality sources have names\n",
    "4. **Result is HLLSet**: All processing produces HLLSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SystemKernel' from 'core.kernel' (/home/alexmy/SGS/SGS_lib/hllset_manifold/core/kernel.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import the kernel\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkernel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SystemKernel, HLLSet, CAS, compute_sha1\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create a kernel instance\u001b[39;00m\n\u001b[32m      5\u001b[39m kernel = SystemKernel(\u001b[33m\"\u001b[39m\u001b[33mDemoKernel\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'SystemKernel' from 'core.kernel' (/home/alexmy/SGS/SGS_lib/hllset_manifold/core/kernel.py)"
     ]
    }
   ],
   "source": [
    "# Import the kernel\n",
    "from core.kernel import SystemKernel, HLLSet, CAS, compute_sha1\n",
    "\n",
    "# Create a kernel instance\n",
    "kernel = SystemKernel(\"DemoKernel\")\n",
    "print(f\"Kernel initialized: {kernel.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Absorb External Reality\n",
    "\n",
    "External reality sources are the only place with semantic names. Once absorbed, they become content-addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define external reality sources (semantic names allowed here only)\n",
    "reality_sources = {\n",
    "    \"quantum_field\": {\"superposition\", \"entanglement\", \"wave\", \"particle\"},\n",
    "    \"classical_field\": {\"position\", \"momentum\", \"trajectory\", \"deterministic\"},\n",
    "    \"consciousness\": {\"awareness\", \"experience\", \"reflection\", \"choice\"},\n",
    "}\n",
    "\n",
    "# Absorb into kernel\n",
    "hashes = {}\n",
    "for name, content in reality_sources.items():\n",
    "    h = kernel.absorb_reality(name, content)\n",
    "    hashes[name] = h\n",
    "    hllset = kernel.get(h)\n",
    "    print(f\"{name:20s} → {h[:16]}... (|A| ≈ {hllset.cardinality():.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Content-Addressed Naming\n",
    "\n",
    "The SHA1 hash is computed from the register contents, not assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an HLLSet and verify its name\n",
    "hll = kernel.get(hashes[\"quantum_field\"])\n",
    "\n",
    "print(\"\\nVerifying HLLSet details:\", f\"{hll.cardinality():.1f}\")\n",
    "\n",
    "print(f\"HLLSet: {hll}\")\n",
    "print(f\"Full SHA1: {hll.name}\")\n",
    "print(f\"Short name: {hll.short_name}\")\n",
    "print(f\"Cardinality: {hll.cardinality():.1f}\")\n",
    "\n",
    "# Verify: re-compute SHA1 from register contents\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "registers = hll.get_register_vector()\n",
    "computed_hash = hashlib.sha1(registers.tobytes()).hexdigest()\n",
    "\n",
    "print(f\"\\nComputed hash matches: {computed_hash == hll.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demonstrate Immutability\n",
    "\n",
    "Adding tokens returns a NEW HLLSet with a NEW hash. The original is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original quantum field\n",
    "original_hash = hashes[\"quantum_field\"]\n",
    "original = kernel.get(original_hash)\n",
    "\n",
    "print(f\"Original: {original.short_name}... |A|={original.cardinality()}\")\n",
    "\n",
    "# Add tokens - returns NEW HLLSet\n",
    "new_hash = kernel.add_to(original_hash, [\"decoherence\", \"measurement\"])\n",
    "modified = kernel.get(new_hash)\n",
    "\n",
    "print(f\"Modified: {modified.short_name}... |A|={modified.cardinality()}\")\n",
    "\n",
    "# Original is unchanged!\n",
    "original_check = kernel.get(original_hash)\n",
    "print(f\"\\nOriginal after 'add': {original_check.short_name}... |A|={original_check.cardinality()}\")\n",
    "print(f\"Original unchanged: {original.name == original_check.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Operations\n",
    "\n",
    "Union, intersection, and difference all return NEW HLLSets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union: quantum ∪ classical\n",
    "union_hash = kernel.union(hashes[\"quantum_field\"], hashes[\"classical_field\"])\n",
    "union_hll = kernel.get(union_hash)\n",
    "\n",
    "print(f\"Union: quantum ∪ classical\")\n",
    "print(f\"  Result: {union_hll.short_name}... |A|={union_hll.cardinality()}\")\n",
    "print(f\"  Expected: ~8 (4 + 4, but with possible overlap)\")\n",
    "\n",
    "# Intersection: quantum ∩ classical\n",
    "inter_hash = kernel.intersection(hashes[\"quantum_field\"], hashes[\"classical_field\"])\n",
    "inter_hll = kernel.get(inter_hash)\n",
    "\n",
    "print(f\"\\nIntersection: quantum ∩ classical\")\n",
    "print(f\"  Result: {inter_hll.short_name}... |A|={inter_hll.cardinality()}\")\n",
    "print(f\"  (Likely ~0 since quantum and classical are distinct)\")\n",
    "\n",
    "# Triple union\n",
    "triple_hash = kernel.union(union_hash, hashes[\"consciousness\"])\n",
    "triple_hll = kernel.get(triple_hash)\n",
    "\n",
    "print(f\"\\nTriple Union: (quantum ∪ classical) ∪ consciousness\")\n",
    "print(f\"  Result: {triple_hll.short_name}... |A|={triple_hll.cardinality()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore the CAS\n",
    "\n",
    "Content-Addressed Store: simple hash → HLLSet mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all stored HLLSets\n",
    "print(f\"CAS contains {len(kernel.cas)} HLLSets:\\n\")\n",
    "\n",
    "for i, h in enumerate(kernel.cas.keys()):\n",
    "    hll = kernel.cas.get(h)\n",
    "    print(f\"{i+1:2d}. {h[:20]}... |A|={hll.cardinality():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BSS Morphisms\n",
    "\n",
    "Establish relationships between HLLSets using Bell State Similarity (τ-ρ duality).\n",
    "\n",
    "- **τ (inclusion tolerance)**: minimum required overlap\n",
    "- **ρ (exclusion intolerance)**: maximum allowed difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.kernel import BSSMetrics\n",
    "\n",
    "# Compute BSS between quantum and classical\n",
    "q = kernel.get(hashes[\"quantum_field\"])\n",
    "c = kernel.get(hashes[\"classical_field\"])\n",
    "\n",
    "bss = BSSMetrics.compute(q, c, tau=0.5, rho=0.3)\n",
    "\n",
    "print(f\"BSS Metrics (quantum → classical):\")\n",
    "print(f\"  BSSτ (inclusion): {bss.bss_tau:.3f} (need ≥ {bss.tau})\")\n",
    "print(f\"  BSSρ (exclusion): {bss.bss_rho:.3f} (need ≤ {bss.rho})\")\n",
    "print(f\"  Morphism exists: {bss.is_satisfied}\")\n",
    "\n",
    "# Try to establish morphism\n",
    "morph_hash = kernel.establish_morphism(\n",
    "    hashes[\"quantum_field\"],\n",
    "    hashes[\"classical_field\"],\n",
    "    tau=0.9,   # Require 90% inclusion\n",
    "    rho=0.1    # Allow up to 10% exclusion\n",
    ")\n",
    "\n",
    "if morph_hash:\n",
    "    print(f\"\\n✓ Morphism established: {morph_hash[:16]}...\")\n",
    "else:\n",
    "    print(f\"\\n✗ Morphism not established (constraints not satisfied)\")\n",
    "\n",
    "print(f\"\\nTotal morphisms in category: {len(kernel.category.morphisms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Noether Conservation\n",
    "\n",
    "The conservation law: **|N| - |D| = 0**\n",
    "\n",
    "- **|N| (novelty)**: New information entering the system\n",
    "- **|D| (drift)**: Information leaving/changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Noether Current (Φ): {kernel.category.noether_phi:.6f}\")\n",
    "print(f\"Novelty |N|: {kernel.category.novelty:.2f}\")\n",
    "print(f\"Drift |D|: {kernel.category.drift:.2f}\")\n",
    "print(f\"Conserved: {kernel.category.is_conserved}\")\n",
    "\n",
    "# Creating morphisms adds novelty\n",
    "print(\"\\nCreating more morphisms...\")\n",
    "for i in range(3):\n",
    "    kernel.establish_morphism(\n",
    "        hashes[\"quantum_field\"],\n",
    "        hashes[\"consciousness\"],\n",
    "        tau=0.9, rho=0.1\n",
    "    )\n",
    "\n",
    "print(f\"Noether Φ after: {kernel.category.noether_phi:.6f}\")\n",
    "print(f\"Morphism count: {len(kernel.category.morphisms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Direct HLLSet Manipulation\n",
    "\n",
    "You can also work with HLLSets directly without the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HLLSets directly\n",
    "from core.kernel import HLL, P_BITS\n",
    "\n",
    "# Empty HLLSet\n",
    "empty = HLLSet(HLL(P_BITS=P_BITS))\n",
    "print(f\"Empty: {empty}\")\n",
    "\n",
    "# Add tokens\n",
    "hll_a = empty.add([\"a\", \"b\", \"c\"])\n",
    "hll_b = empty.add([\"b\", \"c\", \"d\"])\n",
    "\n",
    "print(f\"A: {hll_a}\")\n",
    "print(f\"B: {hll_b}\")\n",
    "\n",
    "# Operations\n",
    "hll_union = hll_a.union(hll_b)\n",
    "hll_inter = hll_a.intersection(hll_b)\n",
    "\n",
    "print(f\"\\nA ∪ B: {hll_union}\")\n",
    "print(f\"A ∩ B: {hll_inter}\")\n",
    "\n",
    "# Similarity\n",
    "sim = hll_a.similarity(hll_b)\n",
    "print(f\"\\nSimilarity(A, B): {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Experiment: Building Complex Structures\n",
    "\n",
    "Build up complex structures through composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a lattice-like structure\n",
    "print(\"Building concept lattice...\\n\")\n",
    "\n",
    "# Base concepts\n",
    "matter = kernel.absorb_reality(\"matter\", {\"mass\", \"energy\", \"spin\"})\n",
    "field = kernel.absorb_reality(\"field\", {\"wave\", \"oscillation\", \"energy\"})\n",
    "particle = kernel.absorb_reality(\"particle\", {\"mass\", \"position\", \"momentum\"})\n",
    "\n",
    "print(\"Base concepts:\")\n",
    "for name, h in [(\"matter\", matter), (\"field\", field), (\"particle\", particle)]:\n",
    "    hll = kernel.get(h)\n",
    "    print(f\"  {name:12s} → {h[:16]}... |A|={hll.cardinality():.1f}\")\n",
    "\n",
    "# Composite concepts\n",
    "wave_particle = kernel.union(field, particle)\n",
    "quantum_matter = kernel.intersection(matter, field)\n",
    "classical_matter = kernel.difference(matter, field)\n",
    "\n",
    "print(\"\\nComposite concepts:\")\n",
    "for name, h in [(\"wave_particle\", wave_particle), (\"quantum_matter\", quantum_matter), (\"classical_matter\", classical_matter)]:\n",
    "    hll = kernel.get(h)\n",
    "    print(f\"  {name:18s} → {h[:16]}... |A|={hll.cardinality():.1f}\")\n",
    "\n",
    "print(f\"\\nCAS now contains {len(kernel.cas)} HLLSets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Kernel Status\n",
    "\n",
    "Summary of the current kernel state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = kernel.status()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KERNEL STATUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for key, value in status.items():\n",
    "    if key == \"stats\":\n",
    "        print(f\"\\n{key}:\")\n",
    "        for k, v in value.items():\n",
    "            if k == \"operations\":\n",
    "                print(f\"    operations:\")\n",
    "                for op, count in v.items():\n",
    "                    print(f\"      {op}: {count}\")\n",
    "            else:\n",
    "                print(f\"    {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Content-addressed storage**: HLLSets are named by SHA1 of their contents\n",
    "2. **Immutability**: All operations return new HLLSets\n",
    "3. **CAS**: Simple hash → HLLSet mapping without graph traversal\n",
    "4. **BSS morphisms**: τ-ρ constrained relationships between HLLSets\n",
    "5. **Noether conservation**: |N| - |D| = 0 tracking\n",
    "\n",
    "Feel free to experiment with your own operations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hllset-manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
